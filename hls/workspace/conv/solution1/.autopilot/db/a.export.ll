; ModuleID = '/home/sergiu/git/lic/hls/workspace/conv/solution1/.autopilot/db/a.o.2.bc'
target datalayout = "e-p:64:64:64-i1:8:8-i8:8:8-i16:16:16-i32:32:32-i64:64:64-f32:32:32-f64:64:64-v64:64:64-v128:128:128-a0:0:64-s0:64:64-f80:128:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

@conv_str = internal unnamed_addr constant [5 x i8] c"conv\00"
@L_conv_label4_str = internal unnamed_addr constant [14 x i8] c"L_conv_label4\00"
@p_str1 = private unnamed_addr constant [1 x i8] zeroinitializer, align 1
@p_str = private unnamed_addr constant [12 x i8] c"conv_label4\00", align 1

declare i32 @llvm.part.select.i32(i32, i32, i32) nounwind readnone

declare void @llvm.dbg.value(metadata, i64, metadata) nounwind readnone

define void @conv([6728 x float]* %output_r, [1024 x float]* %image_r, [128 x float]* %weight, [8 x float]* %bias) nounwind uwtable {
  call void (...)* @_ssdm_op_SpecBitsMap([6728 x float]* %output_r) nounwind, !map !13
  call void (...)* @_ssdm_op_SpecBitsMap([1024 x float]* %image_r) nounwind, !map !20
  call void (...)* @_ssdm_op_SpecBitsMap([128 x float]* %weight) nounwind, !map !27
  call void (...)* @_ssdm_op_SpecBitsMap([8 x float]* %bias) nounwind, !map !33
  call void (...)* @_ssdm_op_SpecTopModule([5 x i8]* @conv_str) nounwind
  br label %.preheader

.preheader:                                       ; preds = %.preheader.preheader, %0
  %indvar_flatten = phi i8 [ 0, %0 ], [ %indvar_flatten_next, %.preheader.preheader ]
  %filter = phi i4 [ 0, %0 ], [ %tmp_mid2_v, %.preheader.preheader ]
  %i = phi i5 [ 0, %0 ], [ %i_1, %.preheader.preheader ]
  %exitcond_flatten = icmp eq i8 %indvar_flatten, -24
  %indvar_flatten_next = add i8 %indvar_flatten, 1
  br i1 %exitcond_flatten, label %1, label %.preheader.preheader

.preheader.preheader:                             ; preds = %.preheader
  %filter_1 = add i4 1, %filter
  call void (...)* @_ssdm_op_SpecLoopName([14 x i8]* @L_conv_label4_str)
  %empty = call i32 (...)* @_ssdm_op_SpecLoopTripCount(i64 232, i64 232, i64 232) nounwind
  %exitcond = icmp eq i5 %i, -3
  %i_mid2 = select i1 %exitcond, i5 0, i5 %i
  %tmp_mid2_v = select i1 %exitcond, i4 %filter_1, i4 %filter
  %tmp_mid2 = zext i4 %tmp_mid2_v to i64
  %tmp_mid2_cast6 = zext i4 %tmp_mid2_v to i13
  %tmp_mid2_cast5 = zext i4 %tmp_mid2_v to i8
  %tmp_mid2_cast4 = zext i4 %tmp_mid2_v to i7
  %tmp_mid2_cast4_cast = zext i4 %tmp_mid2_v to i6
  %tmp_mid2_cast = zext i4 %tmp_mid2_v to i5
  %weight_addr = getelementptr [128 x float]* %weight, i64 0, i64 %tmp_mid2
  %tmp = add i5 8, %tmp_mid2_cast
  %tmp_cast = zext i5 %tmp to i64
  %weight_addr_1 = getelementptr [128 x float]* %weight, i64 0, i64 %tmp_cast
  %tmp_3 = call i64 @_ssdm_op_BitConcatenate.i64.i60.i4(i60 1, i4 %tmp_mid2_v)
  %weight_addr_2 = getelementptr [128 x float]* %weight, i64 0, i64 %tmp_3
  %tmp_4 = add i6 24, %tmp_mid2_cast4_cast
  %tmp_151_cast = zext i6 %tmp_4 to i64
  %weight_addr_3 = getelementptr [128 x float]* %weight, i64 0, i64 %tmp_151_cast
  %tmp_9 = call i64 @_ssdm_op_BitConcatenate.i64.i60.i4(i60 2, i4 %tmp_mid2_v)
  %weight_addr_4 = getelementptr [128 x float]* %weight, i64 0, i64 %tmp_9
  %tmp_15 = add i6 -24, %tmp_mid2_cast4_cast
  %tmp_153_cast = zext i6 %tmp_15 to i64
  %weight_addr_5 = getelementptr [128 x float]* %weight, i64 0, i64 %tmp_153_cast
  %tmp_20 = call i64 @_ssdm_op_BitConcatenate.i64.i60.i4(i60 3, i4 %tmp_mid2_v)
  %weight_addr_6 = getelementptr [128 x float]* %weight, i64 0, i64 %tmp_20
  %tmp_25 = add i7 56, %tmp_mid2_cast4
  %tmp_155_cast = zext i7 %tmp_25 to i64
  %weight_addr_7 = getelementptr [128 x float]* %weight, i64 0, i64 %tmp_155_cast
  %tmp_30 = call i64 @_ssdm_op_BitConcatenate.i64.i60.i4(i60 4, i4 %tmp_mid2_v)
  %weight_addr_8 = getelementptr [128 x float]* %weight, i64 0, i64 %tmp_30
  %tmp_35 = add i7 -56, %tmp_mid2_cast4
  %tmp_157_cast = zext i7 %tmp_35 to i64
  %weight_addr_9 = getelementptr [128 x float]* %weight, i64 0, i64 %tmp_157_cast
  %tmp_40 = call i64 @_ssdm_op_BitConcatenate.i64.i60.i4(i60 5, i4 %tmp_mid2_v)
  %weight_addr_10 = getelementptr [128 x float]* %weight, i64 0, i64 %tmp_40
  %tmp_45 = add i7 -40, %tmp_mid2_cast4
  %tmp_159_cast = zext i7 %tmp_45 to i64
  %weight_addr_11 = getelementptr [128 x float]* %weight, i64 0, i64 %tmp_159_cast
  %tmp_50 = call i64 @_ssdm_op_BitConcatenate.i64.i60.i4(i60 6, i4 %tmp_mid2_v)
  %weight_addr_12 = getelementptr [128 x float]* %weight, i64 0, i64 %tmp_50
  %tmp_161_cast7 = sext i6 %tmp_15 to i7
  %tmp_161_cast = zext i7 %tmp_161_cast7 to i64
  %weight_addr_13 = getelementptr [128 x float]* %weight, i64 0, i64 %tmp_161_cast
  %tmp_55 = call i64 @_ssdm_op_BitConcatenate.i64.i60.i4(i60 7, i4 %tmp_mid2_v)
  %weight_addr_14 = getelementptr [128 x float]* %weight, i64 0, i64 %tmp_55
  %tmp_60 = add i8 120, %tmp_mid2_cast5
  %tmp_163_cast = zext i8 %tmp_60 to i64
  %weight_addr_15 = getelementptr [128 x float]* %weight, i64 0, i64 %tmp_163_cast
  call void (...)* @_ssdm_op_SpecLoopName([12 x i8]* @p_str) nounwind
  %tmp_1 = call i32 (...)* @_ssdm_op_SpecRegionBegin([12 x i8]* @p_str) nounwind
  call void (...)* @_ssdm_op_SpecPipeline(i32 -1, i32 1, i32 1, i32 0, [1 x i8]* @p_str1) nounwind
  %tmp_3_cast = zext i5 %i_mid2 to i13
  %tmp_65 = mul i13 232, %tmp_3_cast
  %tmp_70 = add i13 %tmp_mid2_cast6, %tmp_65
  %tmp_165_cast = zext i13 %tmp_70 to i64
  %output_addr = getelementptr [6728 x float]* %output_r, i64 0, i64 %tmp_165_cast
  %tmp_75 = add i13 8, %tmp_65
  %tmp_80 = add i13 %tmp_mid2_cast6, %tmp_75
  %tmp_167_cast = zext i13 %tmp_80 to i64
  %output_addr_1 = getelementptr [6728 x float]* %output_r, i64 0, i64 %tmp_167_cast
  %tmp_85 = add i13 16, %tmp_65
  %tmp_90 = add i13 %tmp_mid2_cast6, %tmp_85
  %tmp_169_cast = zext i13 %tmp_90 to i64
  %output_addr_2 = getelementptr [6728 x float]* %output_r, i64 0, i64 %tmp_169_cast
  %tmp_95 = add i13 24, %tmp_65
  %tmp_100 = add i13 %tmp_mid2_cast6, %tmp_95
  %tmp_171_cast = zext i13 %tmp_100 to i64
  %output_addr_3 = getelementptr [6728 x float]* %output_r, i64 0, i64 %tmp_171_cast
  %tmp_105 = add i13 32, %tmp_65
  %tmp_110 = add i13 %tmp_mid2_cast6, %tmp_105
  %tmp_173_cast = zext i13 %tmp_110 to i64
  %output_addr_4 = getelementptr [6728 x float]* %output_r, i64 0, i64 %tmp_173_cast
  %tmp_115 = add i13 40, %tmp_65
  %tmp_120 = add i13 %tmp_mid2_cast6, %tmp_115
  %tmp_175_cast = zext i13 %tmp_120 to i64
  %output_addr_5 = getelementptr [6728 x float]* %output_r, i64 0, i64 %tmp_175_cast
  %tmp_125 = add i13 48, %tmp_65
  %tmp_130 = add i13 %tmp_mid2_cast6, %tmp_125
  %tmp_177_cast = zext i13 %tmp_130 to i64
  %output_addr_6 = getelementptr [6728 x float]* %output_r, i64 0, i64 %tmp_177_cast
  %tmp_135 = add i13 56, %tmp_65
  %tmp_140 = add i13 %tmp_mid2_cast6, %tmp_135
  %tmp_179_cast = zext i13 %tmp_140 to i64
  %output_addr_7 = getelementptr [6728 x float]* %output_r, i64 0, i64 %tmp_179_cast
  %tmp_145 = add i13 64, %tmp_65
  %tmp_149 = add i13 %tmp_mid2_cast6, %tmp_145
  %tmp_181_cast = zext i13 %tmp_149 to i64
  %output_addr_8 = getelementptr [6728 x float]* %output_r, i64 0, i64 %tmp_181_cast
  %tmp_150 = add i13 72, %tmp_65
  %tmp_151 = add i13 %tmp_mid2_cast6, %tmp_150
  %tmp_183_cast = zext i13 %tmp_151 to i64
  %output_addr_9 = getelementptr [6728 x float]* %output_r, i64 0, i64 %tmp_183_cast
  %tmp_152 = add i13 80, %tmp_65
  %tmp_153 = add i13 %tmp_mid2_cast6, %tmp_152
  %tmp_185_cast = zext i13 %tmp_153 to i64
  %output_addr_10 = getelementptr [6728 x float]* %output_r, i64 0, i64 %tmp_185_cast
  %tmp_154 = add i13 88, %tmp_65
  %tmp_155 = add i13 %tmp_mid2_cast6, %tmp_154
  %tmp_187_cast = zext i13 %tmp_155 to i64
  %output_addr_11 = getelementptr [6728 x float]* %output_r, i64 0, i64 %tmp_187_cast
  %tmp_156 = add i13 96, %tmp_65
  %tmp_157 = add i13 %tmp_mid2_cast6, %tmp_156
  %tmp_189_cast = zext i13 %tmp_157 to i64
  %output_addr_12 = getelementptr [6728 x float]* %output_r, i64 0, i64 %tmp_189_cast
  %tmp_158 = add i13 104, %tmp_65
  %tmp_159 = add i13 %tmp_mid2_cast6, %tmp_158
  %tmp_191_cast = zext i13 %tmp_159 to i64
  %output_addr_13 = getelementptr [6728 x float]* %output_r, i64 0, i64 %tmp_191_cast
  %tmp_160 = add i13 112, %tmp_65
  %tmp_161 = add i13 %tmp_mid2_cast6, %tmp_160
  %tmp_193_cast = zext i13 %tmp_161 to i64
  %output_addr_14 = getelementptr [6728 x float]* %output_r, i64 0, i64 %tmp_193_cast
  %tmp_162 = add i13 120, %tmp_65
  %tmp_163 = add i13 %tmp_mid2_cast6, %tmp_162
  %tmp_195_cast = zext i13 %tmp_163 to i64
  %output_addr_15 = getelementptr [6728 x float]* %output_r, i64 0, i64 %tmp_195_cast
  %tmp_164 = add i13 128, %tmp_65
  %tmp_165 = add i13 %tmp_mid2_cast6, %tmp_164
  %tmp_197_cast = zext i13 %tmp_165 to i64
  %output_addr_16 = getelementptr [6728 x float]* %output_r, i64 0, i64 %tmp_197_cast
  %tmp_166 = add i13 136, %tmp_65
  %tmp_167 = add i13 %tmp_mid2_cast6, %tmp_166
  %tmp_199_cast = zext i13 %tmp_167 to i64
  %output_addr_17 = getelementptr [6728 x float]* %output_r, i64 0, i64 %tmp_199_cast
  %tmp_168 = add i13 144, %tmp_65
  %tmp_169 = add i13 %tmp_mid2_cast6, %tmp_168
  %tmp_201_cast = zext i13 %tmp_169 to i64
  %output_addr_18 = getelementptr [6728 x float]* %output_r, i64 0, i64 %tmp_201_cast
  %tmp_170 = add i13 152, %tmp_65
  %tmp_171 = add i13 %tmp_mid2_cast6, %tmp_170
  %tmp_203_cast = zext i13 %tmp_171 to i64
  %output_addr_19 = getelementptr [6728 x float]* %output_r, i64 0, i64 %tmp_203_cast
  %tmp_172 = add i13 160, %tmp_65
  %tmp_173 = add i13 %tmp_mid2_cast6, %tmp_172
  %tmp_205_cast = zext i13 %tmp_173 to i64
  %output_addr_20 = getelementptr [6728 x float]* %output_r, i64 0, i64 %tmp_205_cast
  %tmp_174 = add i13 168, %tmp_65
  %tmp_175 = add i13 %tmp_mid2_cast6, %tmp_174
  %tmp_207_cast = zext i13 %tmp_175 to i64
  %output_addr_21 = getelementptr [6728 x float]* %output_r, i64 0, i64 %tmp_207_cast
  %tmp_176 = add i13 176, %tmp_65
  %tmp_177 = add i13 %tmp_mid2_cast6, %tmp_176
  %tmp_209_cast = zext i13 %tmp_177 to i64
  %output_addr_22 = getelementptr [6728 x float]* %output_r, i64 0, i64 %tmp_209_cast
  %tmp_178 = add i13 184, %tmp_65
  %tmp_179 = add i13 %tmp_mid2_cast6, %tmp_178
  %tmp_211_cast = zext i13 %tmp_179 to i64
  %output_addr_23 = getelementptr [6728 x float]* %output_r, i64 0, i64 %tmp_211_cast
  %tmp_180 = add i13 192, %tmp_65
  %tmp_181 = add i13 %tmp_mid2_cast6, %tmp_180
  %tmp_213_cast = zext i13 %tmp_181 to i64
  %output_addr_24 = getelementptr [6728 x float]* %output_r, i64 0, i64 %tmp_213_cast
  %tmp_182 = add i13 200, %tmp_65
  %tmp_183 = add i13 %tmp_mid2_cast6, %tmp_182
  %tmp_215_cast = zext i13 %tmp_183 to i64
  %output_addr_25 = getelementptr [6728 x float]* %output_r, i64 0, i64 %tmp_215_cast
  %tmp_184 = add i13 208, %tmp_65
  %tmp_185 = add i13 %tmp_mid2_cast6, %tmp_184
  %tmp_217_cast = zext i13 %tmp_185 to i64
  %output_addr_26 = getelementptr [6728 x float]* %output_r, i64 0, i64 %tmp_217_cast
  %tmp_186 = add i13 216, %tmp_65
  %tmp_187 = add i13 %tmp_mid2_cast6, %tmp_186
  %tmp_219_cast = zext i13 %tmp_187 to i64
  %output_addr_27 = getelementptr [6728 x float]* %output_r, i64 0, i64 %tmp_219_cast
  %tmp_188 = add i13 224, %tmp_65
  %tmp_189 = add i13 %tmp_mid2_cast6, %tmp_188
  %tmp_221_cast = zext i13 %tmp_189 to i64
  %output_addr_28 = getelementptr [6728 x float]* %output_r, i64 0, i64 %tmp_221_cast
  %tmp_190 = call i10 @_ssdm_op_BitConcatenate.i10.i5.i5(i5 %i_mid2, i5 0)
  %tmp_191 = zext i10 %tmp_190 to i64
  %image_addr = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_191
  %tmp_192 = or i10 %tmp_190, 1
  %tmp_193 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_192)
  %image_addr_1 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_193
  %tmp_194 = or i10 %tmp_190, 2
  %tmp_195 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_194)
  %image_addr_2 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_195
  %tmp_196 = or i10 %tmp_190, 3
  %tmp_197 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_196)
  %image_addr_3 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_197
  %tmp_198 = or i10 %tmp_190, 4
  %tmp_199 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_198)
  %image_addr_16 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_199
  %tmp_200 = or i10 %tmp_190, 5
  %tmp_201 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_200)
  %image_addr_20 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_201
  %tmp_202 = or i10 %tmp_190, 6
  %tmp_203 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_202)
  %image_addr_24 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_203
  %tmp_204 = or i10 %tmp_190, 7
  %tmp_205 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_204)
  %image_addr_28 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_205
  %tmp_206 = or i10 %tmp_190, 8
  %tmp_207 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_206)
  %image_addr_32 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_207
  %tmp_208 = or i10 %tmp_190, 9
  %tmp_209 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_208)
  %image_addr_36 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_209
  %tmp_210 = or i10 %tmp_190, 10
  %tmp_211 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_210)
  %image_addr_40 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_211
  %tmp_212 = or i10 %tmp_190, 11
  %tmp_213 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_212)
  %image_addr_44 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_213
  %tmp_214 = or i10 %tmp_190, 12
  %tmp_215 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_214)
  %image_addr_48 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_215
  %tmp_216 = or i10 %tmp_190, 13
  %tmp_217 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_216)
  %image_addr_52 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_217
  %tmp_218 = or i10 %tmp_190, 14
  %tmp_219 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_218)
  %image_addr_56 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_219
  %tmp_220 = or i10 %tmp_190, 15
  %tmp_221 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_220)
  %image_addr_60 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_221
  %tmp_222 = or i10 %tmp_190, 16
  %tmp_223 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_222)
  %image_addr_64 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_223
  %tmp_224 = or i10 %tmp_190, 17
  %tmp_225 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_224)
  %image_addr_68 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_225
  %tmp_226 = or i10 %tmp_190, 18
  %tmp_227 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_226)
  %image_addr_72 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_227
  %tmp_228 = or i10 %tmp_190, 19
  %tmp_229 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_228)
  %image_addr_76 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_229
  %tmp_230 = or i10 %tmp_190, 20
  %tmp_231 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_230)
  %image_addr_80 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_231
  %tmp_232 = or i10 %tmp_190, 21
  %tmp_233 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_232)
  %image_addr_84 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_233
  %tmp_234 = or i10 %tmp_190, 22
  %tmp_235 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_234)
  %image_addr_88 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_235
  %tmp_236 = or i10 %tmp_190, 23
  %tmp_237 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_236)
  %image_addr_92 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_237
  %tmp_238 = or i10 %tmp_190, 24
  %tmp_239 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_238)
  %image_addr_96 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_239
  %tmp_240 = or i10 %tmp_190, 25
  %tmp_241 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_240)
  %image_addr_100 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_241
  %tmp_242 = or i10 %tmp_190, 26
  %tmp_243 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_242)
  %image_addr_104 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_243
  %tmp_244 = or i10 %tmp_190, 27
  %tmp_245 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_244)
  %image_addr_108 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_245
  %tmp_246 = or i10 %tmp_190, 28
  %tmp_247 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_246)
  %image_addr_112 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_247
  %tmp_248 = or i10 %tmp_190, 29
  %tmp_249 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_248)
  %image_addr_116 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_249
  %tmp_250 = or i10 %tmp_190, 30
  %tmp_251 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_250)
  %image_addr_120 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_251
  %tmp_252 = or i10 %tmp_190, 31
  %tmp_253 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_252)
  %image_addr_124 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_253
  %image_load = load float* %image_addr, align 4
  %weight_load = load float* %weight_addr, align 4
  %tmp_s = fmul float %image_load, %weight_load
  %tmp_10 = fadd float %tmp_s, 0.000000e+00
  %image_load_1 = load float* %image_addr_1, align 4
  %weight_load_1 = load float* %weight_addr_1, align 4
  %tmp_10_0_0_1 = fmul float %image_load_1, %weight_load_1
  %tmp_11_0_0_1 = fadd float %tmp_10, %tmp_10_0_0_1
  %image_load_2 = load float* %image_addr_2, align 4
  %weight_load_2 = load float* %weight_addr_2, align 4
  %tmp_10_0_0_2 = fmul float %image_load_2, %weight_load_2
  %tmp_11_0_0_2 = fadd float %tmp_11_0_0_1, %tmp_10_0_0_2
  %image_load_3 = load float* %image_addr_3, align 4
  %weight_load_3 = load float* %weight_addr_3, align 4
  %tmp_10_0_0_3 = fmul float %image_load_3, %weight_load_3
  %tmp_11_0_0_3 = fadd float %tmp_11_0_0_2, %tmp_10_0_0_3
  %i_1 = add i5 1, %i_mid2
  %tmp_254 = call i10 @_ssdm_op_BitConcatenate.i10.i5.i5(i5 %i_1, i5 0)
  %tmp_255 = zext i10 %tmp_254 to i64
  %image_addr_4 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_255
  %tmp_256 = or i10 %tmp_254, 1
  %tmp_257 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_256)
  %image_addr_5 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_257
  %tmp_258 = or i10 %tmp_254, 2
  %tmp_259 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_258)
  %image_addr_6 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_259
  %tmp_260 = or i10 %tmp_254, 3
  %tmp_261 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_260)
  %image_addr_7 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_261
  %tmp_262 = or i10 %tmp_254, 4
  %tmp_263 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_262)
  %image_addr_17 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_263
  %tmp_264 = or i10 %tmp_254, 5
  %tmp_265 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_264)
  %image_addr_21 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_265
  %tmp_266 = or i10 %tmp_254, 6
  %tmp_267 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_266)
  %image_addr_25 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_267
  %tmp_268 = or i10 %tmp_254, 7
  %tmp_269 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_268)
  %image_addr_29 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_269
  %tmp_270 = or i10 %tmp_254, 8
  %tmp_271 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_270)
  %image_addr_33 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_271
  %tmp_272 = or i10 %tmp_254, 9
  %tmp_273 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_272)
  %image_addr_37 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_273
  %tmp_274 = or i10 %tmp_254, 10
  %tmp_275 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_274)
  %image_addr_41 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_275
  %tmp_276 = or i10 %tmp_254, 11
  %tmp_277 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_276)
  %image_addr_45 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_277
  %tmp_278 = or i10 %tmp_254, 12
  %tmp_279 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_278)
  %image_addr_49 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_279
  %tmp_280 = or i10 %tmp_254, 13
  %tmp_281 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_280)
  %image_addr_53 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_281
  %tmp_282 = or i10 %tmp_254, 14
  %tmp_283 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_282)
  %image_addr_57 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_283
  %tmp_284 = or i10 %tmp_254, 15
  %tmp_285 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_284)
  %image_addr_61 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_285
  %tmp_286 = or i10 %tmp_254, 16
  %tmp_287 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_286)
  %image_addr_65 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_287
  %tmp_288 = or i10 %tmp_254, 17
  %tmp_289 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_288)
  %image_addr_69 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_289
  %tmp_290 = or i10 %tmp_254, 18
  %tmp_291 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_290)
  %image_addr_73 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_291
  %tmp_292 = or i10 %tmp_254, 19
  %tmp_293 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_292)
  %image_addr_77 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_293
  %tmp_294 = or i10 %tmp_254, 20
  %tmp_295 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_294)
  %image_addr_81 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_295
  %tmp_296 = or i10 %tmp_254, 21
  %tmp_297 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_296)
  %image_addr_85 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_297
  %tmp_298 = or i10 %tmp_254, 22
  %tmp_299 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_298)
  %image_addr_89 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_299
  %tmp_300 = or i10 %tmp_254, 23
  %tmp_301 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_300)
  %image_addr_93 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_301
  %tmp_302 = or i10 %tmp_254, 24
  %tmp_303 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_302)
  %image_addr_97 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_303
  %tmp_304 = or i10 %tmp_254, 25
  %tmp_305 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_304)
  %image_addr_101 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_305
  %tmp_306 = or i10 %tmp_254, 26
  %tmp_307 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_306)
  %image_addr_105 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_307
  %tmp_308 = or i10 %tmp_254, 27
  %tmp_309 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_308)
  %image_addr_109 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_309
  %tmp_310 = or i10 %tmp_254, 28
  %tmp_311 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_310)
  %image_addr_113 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_311
  %tmp_312 = or i10 %tmp_254, 29
  %tmp_313 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_312)
  %image_addr_117 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_313
  %tmp_314 = or i10 %tmp_254, 30
  %tmp_315 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_314)
  %image_addr_121 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_315
  %tmp_316 = or i10 %tmp_254, 31
  %tmp_317 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_316)
  %image_addr_125 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_317
  %image_load_4 = load float* %image_addr_4, align 4
  %weight_load_4 = load float* %weight_addr_4, align 4
  %tmp_10_0_1 = fmul float %image_load_4, %weight_load_4
  %tmp_11_0_1 = fadd float %tmp_11_0_0_3, %tmp_10_0_1
  %image_load_5 = load float* %image_addr_5, align 4
  %weight_load_5 = load float* %weight_addr_5, align 4
  %tmp_10_0_1_1 = fmul float %image_load_5, %weight_load_5
  %tmp_11_0_1_1 = fadd float %tmp_11_0_1, %tmp_10_0_1_1
  %image_load_6 = load float* %image_addr_6, align 4
  %weight_load_6 = load float* %weight_addr_6, align 4
  %tmp_10_0_1_2 = fmul float %image_load_6, %weight_load_6
  %tmp_11_0_1_2 = fadd float %tmp_11_0_1_1, %tmp_10_0_1_2
  %image_load_7 = load float* %image_addr_7, align 4
  %weight_load_7 = load float* %weight_addr_7, align 4
  %tmp_10_0_1_3 = fmul float %image_load_7, %weight_load_7
  %tmp_11_0_1_3 = fadd float %tmp_11_0_1_2, %tmp_10_0_1_3
  %tmp_9_0_2 = add i5 2, %i_mid2
  %tmp_318 = call i10 @_ssdm_op_BitConcatenate.i10.i5.i5(i5 %tmp_9_0_2, i5 0)
  %tmp_319 = zext i10 %tmp_318 to i64
  %image_addr_8 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_319
  %tmp_320 = or i10 %tmp_318, 1
  %tmp_321 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_320)
  %image_addr_9 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_321
  %tmp_322 = or i10 %tmp_318, 2
  %tmp_323 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_322)
  %image_addr_10 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_323
  %tmp_324 = or i10 %tmp_318, 3
  %tmp_325 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_324)
  %image_addr_11 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_325
  %tmp_326 = or i10 %tmp_318, 4
  %tmp_327 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_326)
  %image_addr_18 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_327
  %tmp_328 = or i10 %tmp_318, 5
  %tmp_329 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_328)
  %image_addr_22 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_329
  %tmp_330 = or i10 %tmp_318, 6
  %tmp_331 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_330)
  %image_addr_26 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_331
  %tmp_332 = or i10 %tmp_318, 7
  %tmp_333 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_332)
  %image_addr_30 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_333
  %tmp_334 = or i10 %tmp_318, 8
  %tmp_335 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_334)
  %image_addr_34 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_335
  %tmp_336 = or i10 %tmp_318, 9
  %tmp_337 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_336)
  %image_addr_38 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_337
  %tmp_338 = or i10 %tmp_318, 10
  %tmp_339 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_338)
  %image_addr_42 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_339
  %tmp_340 = or i10 %tmp_318, 11
  %tmp_341 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_340)
  %image_addr_46 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_341
  %tmp_342 = or i10 %tmp_318, 12
  %tmp_343 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_342)
  %image_addr_50 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_343
  %tmp_344 = or i10 %tmp_318, 13
  %tmp_345 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_344)
  %image_addr_54 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_345
  %tmp_346 = or i10 %tmp_318, 14
  %tmp_347 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_346)
  %image_addr_58 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_347
  %tmp_348 = or i10 %tmp_318, 15
  %tmp_349 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_348)
  %image_addr_62 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_349
  %tmp_350 = or i10 %tmp_318, 16
  %tmp_351 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_350)
  %image_addr_66 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_351
  %tmp_352 = or i10 %tmp_318, 17
  %tmp_353 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_352)
  %image_addr_70 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_353
  %tmp_354 = or i10 %tmp_318, 18
  %tmp_355 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_354)
  %image_addr_74 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_355
  %tmp_356 = or i10 %tmp_318, 19
  %tmp_357 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_356)
  %image_addr_78 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_357
  %tmp_358 = or i10 %tmp_318, 20
  %tmp_359 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_358)
  %image_addr_82 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_359
  %tmp_360 = or i10 %tmp_318, 21
  %tmp_361 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_360)
  %image_addr_86 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_361
  %tmp_362 = or i10 %tmp_318, 22
  %tmp_363 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_362)
  %image_addr_90 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_363
  %tmp_364 = or i10 %tmp_318, 23
  %tmp_365 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_364)
  %image_addr_94 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_365
  %tmp_366 = or i10 %tmp_318, 24
  %tmp_367 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_366)
  %image_addr_98 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_367
  %tmp_368 = or i10 %tmp_318, 25
  %tmp_369 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_368)
  %image_addr_102 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_369
  %tmp_370 = or i10 %tmp_318, 26
  %tmp_371 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_370)
  %image_addr_106 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_371
  %tmp_372 = or i10 %tmp_318, 27
  %tmp_373 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_372)
  %image_addr_110 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_373
  %tmp_374 = or i10 %tmp_318, 28
  %tmp_375 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_374)
  %image_addr_114 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_375
  %tmp_376 = or i10 %tmp_318, 29
  %tmp_377 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_376)
  %image_addr_118 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_377
  %tmp_378 = or i10 %tmp_318, 30
  %tmp_379 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_378)
  %image_addr_122 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_379
  %tmp_380 = or i10 %tmp_318, 31
  %tmp_381 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_380)
  %image_addr_126 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_381
  %image_load_8 = load float* %image_addr_8, align 4
  %weight_load_8 = load float* %weight_addr_8, align 4
  %tmp_10_0_2 = fmul float %image_load_8, %weight_load_8
  %tmp_11_0_2 = fadd float %tmp_11_0_1_3, %tmp_10_0_2
  %image_load_9 = load float* %image_addr_9, align 4
  %weight_load_9 = load float* %weight_addr_9, align 4
  %tmp_10_0_2_1 = fmul float %image_load_9, %weight_load_9
  %tmp_11_0_2_1 = fadd float %tmp_11_0_2, %tmp_10_0_2_1
  %image_load_10 = load float* %image_addr_10, align 4
  %weight_load_10 = load float* %weight_addr_10, align 4
  %tmp_10_0_2_2 = fmul float %image_load_10, %weight_load_10
  %tmp_11_0_2_2 = fadd float %tmp_11_0_2_1, %tmp_10_0_2_2
  %image_load_11 = load float* %image_addr_11, align 4
  %weight_load_11 = load float* %weight_addr_11, align 4
  %tmp_10_0_2_3 = fmul float %image_load_11, %weight_load_11
  %tmp_11_0_2_3 = fadd float %tmp_11_0_2_2, %tmp_10_0_2_3
  %tmp_9_0_3 = add i5 3, %i_mid2
  %tmp_382 = call i10 @_ssdm_op_BitConcatenate.i10.i5.i5(i5 %tmp_9_0_3, i5 0)
  %tmp_383 = zext i10 %tmp_382 to i64
  %image_addr_12 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_383
  %tmp_384 = or i10 %tmp_382, 1
  %tmp_385 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_384)
  %image_addr_13 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_385
  %tmp_386 = or i10 %tmp_382, 2
  %tmp_387 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_386)
  %image_addr_14 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_387
  %tmp_388 = or i10 %tmp_382, 3
  %tmp_389 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_388)
  %image_addr_15 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_389
  %tmp_390 = or i10 %tmp_382, 4
  %tmp_391 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_390)
  %image_addr_19 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_391
  %tmp_392 = or i10 %tmp_382, 5
  %tmp_393 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_392)
  %image_addr_23 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_393
  %tmp_394 = or i10 %tmp_382, 6
  %tmp_395 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_394)
  %image_addr_27 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_395
  %tmp_396 = or i10 %tmp_382, 7
  %tmp_397 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_396)
  %image_addr_31 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_397
  %tmp_398 = or i10 %tmp_382, 8
  %tmp_399 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_398)
  %image_addr_35 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_399
  %tmp_400 = or i10 %tmp_382, 9
  %tmp_401 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_400)
  %image_addr_39 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_401
  %tmp_402 = or i10 %tmp_382, 10
  %tmp_403 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_402)
  %image_addr_43 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_403
  %tmp_404 = or i10 %tmp_382, 11
  %tmp_405 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_404)
  %image_addr_47 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_405
  %tmp_406 = or i10 %tmp_382, 12
  %tmp_407 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_406)
  %image_addr_51 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_407
  %tmp_408 = or i10 %tmp_382, 13
  %tmp_409 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_408)
  %image_addr_55 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_409
  %tmp_410 = or i10 %tmp_382, 14
  %tmp_411 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_410)
  %image_addr_59 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_411
  %tmp_412 = or i10 %tmp_382, 15
  %tmp_413 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_412)
  %image_addr_63 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_413
  %tmp_414 = or i10 %tmp_382, 16
  %tmp_415 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_414)
  %image_addr_67 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_415
  %tmp_416 = or i10 %tmp_382, 17
  %tmp_417 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_416)
  %image_addr_71 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_417
  %tmp_418 = or i10 %tmp_382, 18
  %tmp_419 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_418)
  %image_addr_75 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_419
  %tmp_420 = or i10 %tmp_382, 19
  %tmp_421 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_420)
  %image_addr_79 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_421
  %tmp_422 = or i10 %tmp_382, 20
  %tmp_423 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_422)
  %image_addr_83 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_423
  %tmp_424 = or i10 %tmp_382, 21
  %tmp_425 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_424)
  %image_addr_87 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_425
  %tmp_426 = or i10 %tmp_382, 22
  %tmp_427 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_426)
  %image_addr_91 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_427
  %tmp_428 = or i10 %tmp_382, 23
  %tmp_429 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_428)
  %image_addr_95 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_429
  %tmp_430 = or i10 %tmp_382, 24
  %tmp_431 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_430)
  %image_addr_99 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_431
  %tmp_432 = or i10 %tmp_382, 25
  %tmp_433 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_432)
  %image_addr_103 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_433
  %tmp_434 = or i10 %tmp_382, 26
  %tmp_435 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_434)
  %image_addr_107 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_435
  %tmp_436 = or i10 %tmp_382, 27
  %tmp_437 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_436)
  %image_addr_111 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_437
  %tmp_438 = or i10 %tmp_382, 28
  %tmp_439 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_438)
  %image_addr_115 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_439
  %tmp_440 = or i10 %tmp_382, 29
  %tmp_441 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_440)
  %image_addr_119 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_441
  %tmp_442 = or i10 %tmp_382, 30
  %tmp_443 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_442)
  %image_addr_123 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_443
  %tmp_444 = or i10 %tmp_382, 31
  %tmp_445 = call i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54 0, i10 %tmp_444)
  %image_addr_127 = getelementptr [1024 x float]* %image_r, i64 0, i64 %tmp_445
  %image_load_12 = load float* %image_addr_12, align 4
  %weight_load_12 = load float* %weight_addr_12, align 4
  %tmp_10_0_3 = fmul float %image_load_12, %weight_load_12
  %tmp_11_0_3 = fadd float %tmp_11_0_2_3, %tmp_10_0_3
  %image_load_13 = load float* %image_addr_13, align 4
  %weight_load_13 = load float* %weight_addr_13, align 4
  %tmp_10_0_3_1 = fmul float %image_load_13, %weight_load_13
  %tmp_11_0_3_1 = fadd float %tmp_11_0_3, %tmp_10_0_3_1
  %image_load_14 = load float* %image_addr_14, align 4
  %weight_load_14 = load float* %weight_addr_14, align 4
  %tmp_10_0_3_2 = fmul float %image_load_14, %weight_load_14
  %tmp_11_0_3_2 = fadd float %tmp_11_0_3_1, %tmp_10_0_3_2
  %image_load_15 = load float* %image_addr_15, align 4
  %weight_load_15 = load float* %weight_addr_15, align 4
  %tmp_10_0_3_3 = fmul float %image_load_15, %weight_load_15
  %tmp_11_0_3_3 = fadd float %tmp_11_0_3_2, %tmp_10_0_3_3
  %bias_addr = getelementptr [8 x float]* %bias, i64 0, i64 %tmp_mid2
  %bias_load = load float* %bias_addr, align 4
  %a_assign = fadd float %tmp_11_0_3_3, %bias_load
  %a_assign_to_int = bitcast float %a_assign to i32
  %tmp_2 = call i8 @_ssdm_op_PartSelect.i8.i32.i32.i32(i32 %a_assign_to_int, i32 23, i32 30)
  %tmp_446 = trunc i32 %a_assign_to_int to i23
  %notlhs = icmp ne i8 %tmp_2, -1
  %notrhs = icmp eq i23 %tmp_446, 0
  %tmp_5 = or i1 %notrhs, %notlhs
  %tmp_6 = fcmp ogt float %a_assign, 0.000000e+00
  %tmp_7 = and i1 %tmp_5, %tmp_6
  %a_assign_1 = select i1 %tmp_7, float %a_assign, float 0.000000e+00
  store float %a_assign_1, float* %output_addr, align 4
  %tmp_10_1 = fmul float %image_load_1, %weight_load
  %tmp_11_1 = fadd float %tmp_10_1, 0.000000e+00
  %tmp_10_1_0_1 = fmul float %image_load_2, %weight_load_1
  %tmp_11_1_0_1 = fadd float %tmp_11_1, %tmp_10_1_0_1
  %tmp_10_1_0_2 = fmul float %image_load_3, %weight_load_2
  %tmp_11_1_0_2 = fadd float %tmp_11_1_0_1, %tmp_10_1_0_2
  %image_load_16 = load float* %image_addr_16, align 4
  %tmp_10_1_0_3 = fmul float %image_load_16, %weight_load_3
  %tmp_11_1_0_3 = fadd float %tmp_11_1_0_2, %tmp_10_1_0_3
  %tmp_10_1_1 = fmul float %image_load_5, %weight_load_4
  %tmp_11_1_1 = fadd float %tmp_11_1_0_3, %tmp_10_1_1
  %tmp_10_1_1_1 = fmul float %image_load_6, %weight_load_5
  %tmp_11_1_1_1 = fadd float %tmp_11_1_1, %tmp_10_1_1_1
  %tmp_10_1_1_2 = fmul float %image_load_7, %weight_load_6
  %tmp_11_1_1_2 = fadd float %tmp_11_1_1_1, %tmp_10_1_1_2
  %image_load_17 = load float* %image_addr_17, align 4
  %tmp_10_1_1_3 = fmul float %image_load_17, %weight_load_7
  %tmp_11_1_1_3 = fadd float %tmp_11_1_1_2, %tmp_10_1_1_3
  %tmp_10_1_2 = fmul float %image_load_9, %weight_load_8
  %tmp_11_1_2 = fadd float %tmp_11_1_1_3, %tmp_10_1_2
  %tmp_10_1_2_1 = fmul float %image_load_10, %weight_load_9
  %tmp_11_1_2_1 = fadd float %tmp_11_1_2, %tmp_10_1_2_1
  %tmp_10_1_2_2 = fmul float %image_load_11, %weight_load_10
  %tmp_11_1_2_2 = fadd float %tmp_11_1_2_1, %tmp_10_1_2_2
  %image_load_18 = load float* %image_addr_18, align 4
  %tmp_10_1_2_3 = fmul float %image_load_18, %weight_load_11
  %tmp_11_1_2_3 = fadd float %tmp_11_1_2_2, %tmp_10_1_2_3
  %tmp_10_1_3 = fmul float %image_load_13, %weight_load_12
  %tmp_11_1_3 = fadd float %tmp_11_1_2_3, %tmp_10_1_3
  %tmp_10_1_3_1 = fmul float %image_load_14, %weight_load_13
  %tmp_11_1_3_1 = fadd float %tmp_11_1_3, %tmp_10_1_3_1
  %tmp_10_1_3_2 = fmul float %image_load_15, %weight_load_14
  %tmp_11_1_3_2 = fadd float %tmp_11_1_3_1, %tmp_10_1_3_2
  %image_load_19 = load float* %image_addr_19, align 4
  %tmp_10_1_3_3 = fmul float %image_load_19, %weight_load_15
  %tmp_11_1_3_3 = fadd float %tmp_11_1_3_2, %tmp_10_1_3_3
  %a_assign_2 = fadd float %tmp_11_1_3_3, %bias_load
  %a_assign_2_to_int = bitcast float %a_assign_2 to i32
  %tmp_8 = call i8 @_ssdm_op_PartSelect.i8.i32.i32.i32(i32 %a_assign_2_to_int, i32 23, i32 30)
  %tmp_447 = trunc i32 %a_assign_2_to_int to i23
  %notlhs1 = icmp ne i8 %tmp_8, -1
  %notrhs1 = icmp eq i23 %tmp_447, 0
  %tmp_11 = or i1 %notrhs1, %notlhs1
  %tmp_12 = fcmp ogt float %a_assign_2, 0.000000e+00
  %tmp_13 = and i1 %tmp_11, %tmp_12
  %a_assign_3 = select i1 %tmp_13, float %a_assign_2, float 0.000000e+00
  store float %a_assign_3, float* %output_addr_1, align 4
  %tmp_10_2 = fmul float %image_load_2, %weight_load
  %tmp_11_2 = fadd float %tmp_10_2, 0.000000e+00
  %tmp_10_2_0_1 = fmul float %image_load_3, %weight_load_1
  %tmp_11_2_0_1 = fadd float %tmp_11_2, %tmp_10_2_0_1
  %tmp_10_2_0_2 = fmul float %image_load_16, %weight_load_2
  %tmp_11_2_0_2 = fadd float %tmp_11_2_0_1, %tmp_10_2_0_2
  %image_load_20 = load float* %image_addr_20, align 4
  %tmp_10_2_0_3 = fmul float %image_load_20, %weight_load_3
  %tmp_11_2_0_3 = fadd float %tmp_11_2_0_2, %tmp_10_2_0_3
  %tmp_10_2_1 = fmul float %image_load_6, %weight_load_4
  %tmp_11_2_1 = fadd float %tmp_11_2_0_3, %tmp_10_2_1
  %tmp_10_2_1_1 = fmul float %image_load_7, %weight_load_5
  %tmp_11_2_1_1 = fadd float %tmp_11_2_1, %tmp_10_2_1_1
  %tmp_10_2_1_2 = fmul float %image_load_17, %weight_load_6
  %tmp_11_2_1_2 = fadd float %tmp_11_2_1_1, %tmp_10_2_1_2
  %image_load_21 = load float* %image_addr_21, align 4
  %tmp_10_2_1_3 = fmul float %image_load_21, %weight_load_7
  %tmp_11_2_1_3 = fadd float %tmp_11_2_1_2, %tmp_10_2_1_3
  %tmp_10_2_2 = fmul float %image_load_10, %weight_load_8
  %tmp_11_2_2 = fadd float %tmp_11_2_1_3, %tmp_10_2_2
  %tmp_10_2_2_1 = fmul float %image_load_11, %weight_load_9
  %tmp_11_2_2_1 = fadd float %tmp_11_2_2, %tmp_10_2_2_1
  %tmp_10_2_2_2 = fmul float %image_load_18, %weight_load_10
  %tmp_11_2_2_2 = fadd float %tmp_11_2_2_1, %tmp_10_2_2_2
  %image_load_22 = load float* %image_addr_22, align 4
  %tmp_10_2_2_3 = fmul float %image_load_22, %weight_load_11
  %tmp_11_2_2_3 = fadd float %tmp_11_2_2_2, %tmp_10_2_2_3
  %tmp_10_2_3 = fmul float %image_load_14, %weight_load_12
  %tmp_11_2_3 = fadd float %tmp_11_2_2_3, %tmp_10_2_3
  %tmp_10_2_3_1 = fmul float %image_load_15, %weight_load_13
  %tmp_11_2_3_1 = fadd float %tmp_11_2_3, %tmp_10_2_3_1
  %tmp_10_2_3_2 = fmul float %image_load_19, %weight_load_14
  %tmp_11_2_3_2 = fadd float %tmp_11_2_3_1, %tmp_10_2_3_2
  %image_load_23 = load float* %image_addr_23, align 4
  %tmp_10_2_3_3 = fmul float %image_load_23, %weight_load_15
  %tmp_11_2_3_3 = fadd float %tmp_11_2_3_2, %tmp_10_2_3_3
  %a_assign_4 = fadd float %tmp_11_2_3_3, %bias_load
  %a_assign_4_to_int = bitcast float %a_assign_4 to i32
  %tmp_14 = call i8 @_ssdm_op_PartSelect.i8.i32.i32.i32(i32 %a_assign_4_to_int, i32 23, i32 30)
  %tmp_448 = trunc i32 %a_assign_4_to_int to i23
  %notlhs2 = icmp ne i8 %tmp_14, -1
  %notrhs2 = icmp eq i23 %tmp_448, 0
  %tmp_16 = or i1 %notrhs2, %notlhs2
  %tmp_17 = fcmp ogt float %a_assign_4, 0.000000e+00
  %tmp_18 = and i1 %tmp_16, %tmp_17
  %a_assign_5 = select i1 %tmp_18, float %a_assign_4, float 0.000000e+00
  store float %a_assign_5, float* %output_addr_2, align 4
  %tmp_10_3 = fmul float %image_load_3, %weight_load
  %tmp_11_3 = fadd float %tmp_10_3, 0.000000e+00
  %tmp_10_3_0_1 = fmul float %image_load_16, %weight_load_1
  %tmp_11_3_0_1 = fadd float %tmp_11_3, %tmp_10_3_0_1
  %tmp_10_3_0_2 = fmul float %image_load_20, %weight_load_2
  %tmp_11_3_0_2 = fadd float %tmp_11_3_0_1, %tmp_10_3_0_2
  %image_load_24 = load float* %image_addr_24, align 4
  %tmp_10_3_0_3 = fmul float %image_load_24, %weight_load_3
  %tmp_11_3_0_3 = fadd float %tmp_11_3_0_2, %tmp_10_3_0_3
  %tmp_10_3_1 = fmul float %image_load_7, %weight_load_4
  %tmp_11_3_1 = fadd float %tmp_11_3_0_3, %tmp_10_3_1
  %tmp_10_3_1_1 = fmul float %image_load_17, %weight_load_5
  %tmp_11_3_1_1 = fadd float %tmp_11_3_1, %tmp_10_3_1_1
  %tmp_10_3_1_2 = fmul float %image_load_21, %weight_load_6
  %tmp_11_3_1_2 = fadd float %tmp_11_3_1_1, %tmp_10_3_1_2
  %image_load_25 = load float* %image_addr_25, align 4
  %tmp_10_3_1_3 = fmul float %image_load_25, %weight_load_7
  %tmp_11_3_1_3 = fadd float %tmp_11_3_1_2, %tmp_10_3_1_3
  %tmp_10_3_2 = fmul float %image_load_11, %weight_load_8
  %tmp_11_3_2 = fadd float %tmp_11_3_1_3, %tmp_10_3_2
  %tmp_10_3_2_1 = fmul float %image_load_18, %weight_load_9
  %tmp_11_3_2_1 = fadd float %tmp_11_3_2, %tmp_10_3_2_1
  %tmp_10_3_2_2 = fmul float %image_load_22, %weight_load_10
  %tmp_11_3_2_2 = fadd float %tmp_11_3_2_1, %tmp_10_3_2_2
  %image_load_26 = load float* %image_addr_26, align 4
  %tmp_10_3_2_3 = fmul float %image_load_26, %weight_load_11
  %tmp_11_3_2_3 = fadd float %tmp_11_3_2_2, %tmp_10_3_2_3
  %tmp_10_3_3 = fmul float %image_load_15, %weight_load_12
  %tmp_11_3_3 = fadd float %tmp_11_3_2_3, %tmp_10_3_3
  %tmp_10_3_3_1 = fmul float %image_load_19, %weight_load_13
  %tmp_11_3_3_1 = fadd float %tmp_11_3_3, %tmp_10_3_3_1
  %tmp_10_3_3_2 = fmul float %image_load_23, %weight_load_14
  %tmp_11_3_3_2 = fadd float %tmp_11_3_3_1, %tmp_10_3_3_2
  %image_load_27 = load float* %image_addr_27, align 4
  %tmp_10_3_3_3 = fmul float %image_load_27, %weight_load_15
  %tmp_11_3_3_3 = fadd float %tmp_11_3_3_2, %tmp_10_3_3_3
  %a_assign_6 = fadd float %tmp_11_3_3_3, %bias_load
  %a_assign_6_to_int = bitcast float %a_assign_6 to i32
  %tmp_19 = call i8 @_ssdm_op_PartSelect.i8.i32.i32.i32(i32 %a_assign_6_to_int, i32 23, i32 30)
  %tmp_449 = trunc i32 %a_assign_6_to_int to i23
  %notlhs3 = icmp ne i8 %tmp_19, -1
  %notrhs3 = icmp eq i23 %tmp_449, 0
  %tmp_21 = or i1 %notrhs3, %notlhs3
  %tmp_22 = fcmp ogt float %a_assign_6, 0.000000e+00
  %tmp_23 = and i1 %tmp_21, %tmp_22
  %a_assign_7 = select i1 %tmp_23, float %a_assign_6, float 0.000000e+00
  store float %a_assign_7, float* %output_addr_3, align 4
  %tmp_10_4 = fmul float %image_load_16, %weight_load
  %tmp_11_4 = fadd float %tmp_10_4, 0.000000e+00
  %tmp_10_4_0_1 = fmul float %image_load_20, %weight_load_1
  %tmp_11_4_0_1 = fadd float %tmp_11_4, %tmp_10_4_0_1
  %tmp_10_4_0_2 = fmul float %image_load_24, %weight_load_2
  %tmp_11_4_0_2 = fadd float %tmp_11_4_0_1, %tmp_10_4_0_2
  %image_load_28 = load float* %image_addr_28, align 4
  %tmp_10_4_0_3 = fmul float %image_load_28, %weight_load_3
  %tmp_11_4_0_3 = fadd float %tmp_11_4_0_2, %tmp_10_4_0_3
  %tmp_10_4_1 = fmul float %image_load_17, %weight_load_4
  %tmp_11_4_1 = fadd float %tmp_11_4_0_3, %tmp_10_4_1
  %tmp_10_4_1_1 = fmul float %image_load_21, %weight_load_5
  %tmp_11_4_1_1 = fadd float %tmp_11_4_1, %tmp_10_4_1_1
  %tmp_10_4_1_2 = fmul float %image_load_25, %weight_load_6
  %tmp_11_4_1_2 = fadd float %tmp_11_4_1_1, %tmp_10_4_1_2
  %image_load_29 = load float* %image_addr_29, align 4
  %tmp_10_4_1_3 = fmul float %image_load_29, %weight_load_7
  %tmp_11_4_1_3 = fadd float %tmp_11_4_1_2, %tmp_10_4_1_3
  %tmp_10_4_2 = fmul float %image_load_18, %weight_load_8
  %tmp_11_4_2 = fadd float %tmp_11_4_1_3, %tmp_10_4_2
  %tmp_10_4_2_1 = fmul float %image_load_22, %weight_load_9
  %tmp_11_4_2_1 = fadd float %tmp_11_4_2, %tmp_10_4_2_1
  %tmp_10_4_2_2 = fmul float %image_load_26, %weight_load_10
  %tmp_11_4_2_2 = fadd float %tmp_11_4_2_1, %tmp_10_4_2_2
  %image_load_30 = load float* %image_addr_30, align 4
  %tmp_10_4_2_3 = fmul float %image_load_30, %weight_load_11
  %tmp_11_4_2_3 = fadd float %tmp_11_4_2_2, %tmp_10_4_2_3
  %tmp_10_4_3 = fmul float %image_load_19, %weight_load_12
  %tmp_11_4_3 = fadd float %tmp_11_4_2_3, %tmp_10_4_3
  %tmp_10_4_3_1 = fmul float %image_load_23, %weight_load_13
  %tmp_11_4_3_1 = fadd float %tmp_11_4_3, %tmp_10_4_3_1
  %tmp_10_4_3_2 = fmul float %image_load_27, %weight_load_14
  %tmp_11_4_3_2 = fadd float %tmp_11_4_3_1, %tmp_10_4_3_2
  %image_load_31 = load float* %image_addr_31, align 4
  %tmp_10_4_3_3 = fmul float %image_load_31, %weight_load_15
  %tmp_11_4_3_3 = fadd float %tmp_11_4_3_2, %tmp_10_4_3_3
  %a_assign_8 = fadd float %tmp_11_4_3_3, %bias_load
  %a_assign_8_to_int = bitcast float %a_assign_8 to i32
  %tmp_24 = call i8 @_ssdm_op_PartSelect.i8.i32.i32.i32(i32 %a_assign_8_to_int, i32 23, i32 30)
  %tmp_450 = trunc i32 %a_assign_8_to_int to i23
  %notlhs4 = icmp ne i8 %tmp_24, -1
  %notrhs4 = icmp eq i23 %tmp_450, 0
  %tmp_26 = or i1 %notrhs4, %notlhs4
  %tmp_27 = fcmp ogt float %a_assign_8, 0.000000e+00
  %tmp_28 = and i1 %tmp_26, %tmp_27
  %a_assign_9 = select i1 %tmp_28, float %a_assign_8, float 0.000000e+00
  store float %a_assign_9, float* %output_addr_4, align 4
  %tmp_10_5 = fmul float %image_load_20, %weight_load
  %tmp_11_5 = fadd float %tmp_10_5, 0.000000e+00
  %tmp_10_5_0_1 = fmul float %image_load_24, %weight_load_1
  %tmp_11_5_0_1 = fadd float %tmp_11_5, %tmp_10_5_0_1
  %tmp_10_5_0_2 = fmul float %image_load_28, %weight_load_2
  %tmp_11_5_0_2 = fadd float %tmp_11_5_0_1, %tmp_10_5_0_2
  %image_load_32 = load float* %image_addr_32, align 4
  %tmp_10_5_0_3 = fmul float %image_load_32, %weight_load_3
  %tmp_11_5_0_3 = fadd float %tmp_11_5_0_2, %tmp_10_5_0_3
  %tmp_10_5_1 = fmul float %image_load_21, %weight_load_4
  %tmp_11_5_1 = fadd float %tmp_11_5_0_3, %tmp_10_5_1
  %tmp_10_5_1_1 = fmul float %image_load_25, %weight_load_5
  %tmp_11_5_1_1 = fadd float %tmp_11_5_1, %tmp_10_5_1_1
  %tmp_10_5_1_2 = fmul float %image_load_29, %weight_load_6
  %tmp_11_5_1_2 = fadd float %tmp_11_5_1_1, %tmp_10_5_1_2
  %image_load_33 = load float* %image_addr_33, align 4
  %tmp_10_5_1_3 = fmul float %image_load_33, %weight_load_7
  %tmp_11_5_1_3 = fadd float %tmp_11_5_1_2, %tmp_10_5_1_3
  %tmp_10_5_2 = fmul float %image_load_22, %weight_load_8
  %tmp_11_5_2 = fadd float %tmp_11_5_1_3, %tmp_10_5_2
  %tmp_10_5_2_1 = fmul float %image_load_26, %weight_load_9
  %tmp_11_5_2_1 = fadd float %tmp_11_5_2, %tmp_10_5_2_1
  %tmp_10_5_2_2 = fmul float %image_load_30, %weight_load_10
  %tmp_11_5_2_2 = fadd float %tmp_11_5_2_1, %tmp_10_5_2_2
  %image_load_34 = load float* %image_addr_34, align 4
  %tmp_10_5_2_3 = fmul float %image_load_34, %weight_load_11
  %tmp_11_5_2_3 = fadd float %tmp_11_5_2_2, %tmp_10_5_2_3
  %tmp_10_5_3 = fmul float %image_load_23, %weight_load_12
  %tmp_11_5_3 = fadd float %tmp_11_5_2_3, %tmp_10_5_3
  %tmp_10_5_3_1 = fmul float %image_load_27, %weight_load_13
  %tmp_11_5_3_1 = fadd float %tmp_11_5_3, %tmp_10_5_3_1
  %tmp_10_5_3_2 = fmul float %image_load_31, %weight_load_14
  %tmp_11_5_3_2 = fadd float %tmp_11_5_3_1, %tmp_10_5_3_2
  %image_load_35 = load float* %image_addr_35, align 4
  %tmp_10_5_3_3 = fmul float %image_load_35, %weight_load_15
  %tmp_11_5_3_3 = fadd float %tmp_11_5_3_2, %tmp_10_5_3_3
  %a_assign_s = fadd float %tmp_11_5_3_3, %bias_load
  %a_assign_10_to_int = bitcast float %a_assign_s to i32
  %tmp_29 = call i8 @_ssdm_op_PartSelect.i8.i32.i32.i32(i32 %a_assign_10_to_int, i32 23, i32 30)
  %tmp_451 = trunc i32 %a_assign_10_to_int to i23
  %notlhs5 = icmp ne i8 %tmp_29, -1
  %notrhs5 = icmp eq i23 %tmp_451, 0
  %tmp_31 = or i1 %notrhs5, %notlhs5
  %tmp_32 = fcmp ogt float %a_assign_s, 0.000000e+00
  %tmp_33 = and i1 %tmp_31, %tmp_32
  %a_assign_10 = select i1 %tmp_33, float %a_assign_s, float 0.000000e+00
  store float %a_assign_10, float* %output_addr_5, align 4
  %tmp_10_6 = fmul float %image_load_24, %weight_load
  %tmp_11_6 = fadd float %tmp_10_6, 0.000000e+00
  %tmp_10_6_0_1 = fmul float %image_load_28, %weight_load_1
  %tmp_11_6_0_1 = fadd float %tmp_11_6, %tmp_10_6_0_1
  %tmp_10_6_0_2 = fmul float %image_load_32, %weight_load_2
  %tmp_11_6_0_2 = fadd float %tmp_11_6_0_1, %tmp_10_6_0_2
  %image_load_36 = load float* %image_addr_36, align 4
  %tmp_10_6_0_3 = fmul float %image_load_36, %weight_load_3
  %tmp_11_6_0_3 = fadd float %tmp_11_6_0_2, %tmp_10_6_0_3
  %tmp_10_6_1 = fmul float %image_load_25, %weight_load_4
  %tmp_11_6_1 = fadd float %tmp_11_6_0_3, %tmp_10_6_1
  %tmp_10_6_1_1 = fmul float %image_load_29, %weight_load_5
  %tmp_11_6_1_1 = fadd float %tmp_11_6_1, %tmp_10_6_1_1
  %tmp_10_6_1_2 = fmul float %image_load_33, %weight_load_6
  %tmp_11_6_1_2 = fadd float %tmp_11_6_1_1, %tmp_10_6_1_2
  %image_load_37 = load float* %image_addr_37, align 4
  %tmp_10_6_1_3 = fmul float %image_load_37, %weight_load_7
  %tmp_11_6_1_3 = fadd float %tmp_11_6_1_2, %tmp_10_6_1_3
  %tmp_10_6_2 = fmul float %image_load_26, %weight_load_8
  %tmp_11_6_2 = fadd float %tmp_11_6_1_3, %tmp_10_6_2
  %tmp_10_6_2_1 = fmul float %image_load_30, %weight_load_9
  %tmp_11_6_2_1 = fadd float %tmp_11_6_2, %tmp_10_6_2_1
  %tmp_10_6_2_2 = fmul float %image_load_34, %weight_load_10
  %tmp_11_6_2_2 = fadd float %tmp_11_6_2_1, %tmp_10_6_2_2
  %image_load_38 = load float* %image_addr_38, align 4
  %tmp_10_6_2_3 = fmul float %image_load_38, %weight_load_11
  %tmp_11_6_2_3 = fadd float %tmp_11_6_2_2, %tmp_10_6_2_3
  %tmp_10_6_3 = fmul float %image_load_27, %weight_load_12
  %tmp_11_6_3 = fadd float %tmp_11_6_2_3, %tmp_10_6_3
  %tmp_10_6_3_1 = fmul float %image_load_31, %weight_load_13
  %tmp_11_6_3_1 = fadd float %tmp_11_6_3, %tmp_10_6_3_1
  %tmp_10_6_3_2 = fmul float %image_load_35, %weight_load_14
  %tmp_11_6_3_2 = fadd float %tmp_11_6_3_1, %tmp_10_6_3_2
  %image_load_39 = load float* %image_addr_39, align 4
  %tmp_10_6_3_3 = fmul float %image_load_39, %weight_load_15
  %tmp_11_6_3_3 = fadd float %tmp_11_6_3_2, %tmp_10_6_3_3
  %a_assign_11 = fadd float %tmp_11_6_3_3, %bias_load
  %a_assign_12_to_int = bitcast float %a_assign_11 to i32
  %tmp_34 = call i8 @_ssdm_op_PartSelect.i8.i32.i32.i32(i32 %a_assign_12_to_int, i32 23, i32 30)
  %tmp_452 = trunc i32 %a_assign_12_to_int to i23
  %notlhs6 = icmp ne i8 %tmp_34, -1
  %notrhs6 = icmp eq i23 %tmp_452, 0
  %tmp_36 = or i1 %notrhs6, %notlhs6
  %tmp_37 = fcmp ogt float %a_assign_11, 0.000000e+00
  %tmp_38 = and i1 %tmp_36, %tmp_37
  %a_assign_12 = select i1 %tmp_38, float %a_assign_11, float 0.000000e+00
  store float %a_assign_12, float* %output_addr_6, align 4
  %tmp_10_7 = fmul float %image_load_28, %weight_load
  %tmp_11_7 = fadd float %tmp_10_7, 0.000000e+00
  %tmp_10_7_0_1 = fmul float %image_load_32, %weight_load_1
  %tmp_11_7_0_1 = fadd float %tmp_11_7, %tmp_10_7_0_1
  %tmp_10_7_0_2 = fmul float %image_load_36, %weight_load_2
  %tmp_11_7_0_2 = fadd float %tmp_11_7_0_1, %tmp_10_7_0_2
  %image_load_40 = load float* %image_addr_40, align 4
  %tmp_10_7_0_3 = fmul float %image_load_40, %weight_load_3
  %tmp_11_7_0_3 = fadd float %tmp_11_7_0_2, %tmp_10_7_0_3
  %tmp_10_7_1 = fmul float %image_load_29, %weight_load_4
  %tmp_11_7_1 = fadd float %tmp_11_7_0_3, %tmp_10_7_1
  %tmp_10_7_1_1 = fmul float %image_load_33, %weight_load_5
  %tmp_11_7_1_1 = fadd float %tmp_11_7_1, %tmp_10_7_1_1
  %tmp_10_7_1_2 = fmul float %image_load_37, %weight_load_6
  %tmp_11_7_1_2 = fadd float %tmp_11_7_1_1, %tmp_10_7_1_2
  %image_load_41 = load float* %image_addr_41, align 4
  %tmp_10_7_1_3 = fmul float %image_load_41, %weight_load_7
  %tmp_11_7_1_3 = fadd float %tmp_11_7_1_2, %tmp_10_7_1_3
  %tmp_10_7_2 = fmul float %image_load_30, %weight_load_8
  %tmp_11_7_2 = fadd float %tmp_11_7_1_3, %tmp_10_7_2
  %tmp_10_7_2_1 = fmul float %image_load_34, %weight_load_9
  %tmp_11_7_2_1 = fadd float %tmp_11_7_2, %tmp_10_7_2_1
  %tmp_10_7_2_2 = fmul float %image_load_38, %weight_load_10
  %tmp_11_7_2_2 = fadd float %tmp_11_7_2_1, %tmp_10_7_2_2
  %image_load_42 = load float* %image_addr_42, align 4
  %tmp_10_7_2_3 = fmul float %image_load_42, %weight_load_11
  %tmp_11_7_2_3 = fadd float %tmp_11_7_2_2, %tmp_10_7_2_3
  %tmp_10_7_3 = fmul float %image_load_31, %weight_load_12
  %tmp_11_7_3 = fadd float %tmp_11_7_2_3, %tmp_10_7_3
  %tmp_10_7_3_1 = fmul float %image_load_35, %weight_load_13
  %tmp_11_7_3_1 = fadd float %tmp_11_7_3, %tmp_10_7_3_1
  %tmp_10_7_3_2 = fmul float %image_load_39, %weight_load_14
  %tmp_11_7_3_2 = fadd float %tmp_11_7_3_1, %tmp_10_7_3_2
  %image_load_43 = load float* %image_addr_43, align 4
  %tmp_10_7_3_3 = fmul float %image_load_43, %weight_load_15
  %tmp_11_7_3_3 = fadd float %tmp_11_7_3_2, %tmp_10_7_3_3
  %a_assign_13 = fadd float %tmp_11_7_3_3, %bias_load
  %a_assign_14_to_int = bitcast float %a_assign_13 to i32
  %tmp_39 = call i8 @_ssdm_op_PartSelect.i8.i32.i32.i32(i32 %a_assign_14_to_int, i32 23, i32 30)
  %tmp_453 = trunc i32 %a_assign_14_to_int to i23
  %notlhs7 = icmp ne i8 %tmp_39, -1
  %notrhs7 = icmp eq i23 %tmp_453, 0
  %tmp_41 = or i1 %notrhs7, %notlhs7
  %tmp_42 = fcmp ogt float %a_assign_13, 0.000000e+00
  %tmp_43 = and i1 %tmp_41, %tmp_42
  %a_assign_14 = select i1 %tmp_43, float %a_assign_13, float 0.000000e+00
  store float %a_assign_14, float* %output_addr_7, align 4
  %tmp_10_8 = fmul float %image_load_32, %weight_load
  %tmp_11_8 = fadd float %tmp_10_8, 0.000000e+00
  %tmp_10_8_0_1 = fmul float %image_load_36, %weight_load_1
  %tmp_11_8_0_1 = fadd float %tmp_11_8, %tmp_10_8_0_1
  %tmp_10_8_0_2 = fmul float %image_load_40, %weight_load_2
  %tmp_11_8_0_2 = fadd float %tmp_11_8_0_1, %tmp_10_8_0_2
  %image_load_44 = load float* %image_addr_44, align 4
  %tmp_10_8_0_3 = fmul float %image_load_44, %weight_load_3
  %tmp_11_8_0_3 = fadd float %tmp_11_8_0_2, %tmp_10_8_0_3
  %tmp_10_8_1 = fmul float %image_load_33, %weight_load_4
  %tmp_11_8_1 = fadd float %tmp_11_8_0_3, %tmp_10_8_1
  %tmp_10_8_1_1 = fmul float %image_load_37, %weight_load_5
  %tmp_11_8_1_1 = fadd float %tmp_11_8_1, %tmp_10_8_1_1
  %tmp_10_8_1_2 = fmul float %image_load_41, %weight_load_6
  %tmp_11_8_1_2 = fadd float %tmp_11_8_1_1, %tmp_10_8_1_2
  %image_load_45 = load float* %image_addr_45, align 4
  %tmp_10_8_1_3 = fmul float %image_load_45, %weight_load_7
  %tmp_11_8_1_3 = fadd float %tmp_11_8_1_2, %tmp_10_8_1_3
  %tmp_10_8_2 = fmul float %image_load_34, %weight_load_8
  %tmp_11_8_2 = fadd float %tmp_11_8_1_3, %tmp_10_8_2
  %tmp_10_8_2_1 = fmul float %image_load_38, %weight_load_9
  %tmp_11_8_2_1 = fadd float %tmp_11_8_2, %tmp_10_8_2_1
  %tmp_10_8_2_2 = fmul float %image_load_42, %weight_load_10
  %tmp_11_8_2_2 = fadd float %tmp_11_8_2_1, %tmp_10_8_2_2
  %image_load_46 = load float* %image_addr_46, align 4
  %tmp_10_8_2_3 = fmul float %image_load_46, %weight_load_11
  %tmp_11_8_2_3 = fadd float %tmp_11_8_2_2, %tmp_10_8_2_3
  %tmp_10_8_3 = fmul float %image_load_35, %weight_load_12
  %tmp_11_8_3 = fadd float %tmp_11_8_2_3, %tmp_10_8_3
  %tmp_10_8_3_1 = fmul float %image_load_39, %weight_load_13
  %tmp_11_8_3_1 = fadd float %tmp_11_8_3, %tmp_10_8_3_1
  %tmp_10_8_3_2 = fmul float %image_load_43, %weight_load_14
  %tmp_11_8_3_2 = fadd float %tmp_11_8_3_1, %tmp_10_8_3_2
  %image_load_47 = load float* %image_addr_47, align 4
  %tmp_10_8_3_3 = fmul float %image_load_47, %weight_load_15
  %tmp_11_8_3_3 = fadd float %tmp_11_8_3_2, %tmp_10_8_3_3
  %a_assign_15 = fadd float %tmp_11_8_3_3, %bias_load
  %a_assign_16_to_int = bitcast float %a_assign_15 to i32
  %tmp_44 = call i8 @_ssdm_op_PartSelect.i8.i32.i32.i32(i32 %a_assign_16_to_int, i32 23, i32 30)
  %tmp_454 = trunc i32 %a_assign_16_to_int to i23
  %notlhs8 = icmp ne i8 %tmp_44, -1
  %notrhs8 = icmp eq i23 %tmp_454, 0
  %tmp_46 = or i1 %notrhs8, %notlhs8
  %tmp_47 = fcmp ogt float %a_assign_15, 0.000000e+00
  %tmp_48 = and i1 %tmp_46, %tmp_47
  %a_assign_16 = select i1 %tmp_48, float %a_assign_15, float 0.000000e+00
  store float %a_assign_16, float* %output_addr_8, align 4
  %tmp_10_9 = fmul float %image_load_36, %weight_load
  %tmp_11_9 = fadd float %tmp_10_9, 0.000000e+00
  %tmp_10_9_0_1 = fmul float %image_load_40, %weight_load_1
  %tmp_11_9_0_1 = fadd float %tmp_11_9, %tmp_10_9_0_1
  %tmp_10_9_0_2 = fmul float %image_load_44, %weight_load_2
  %tmp_11_9_0_2 = fadd float %tmp_11_9_0_1, %tmp_10_9_0_2
  %image_load_48 = load float* %image_addr_48, align 4
  %tmp_10_9_0_3 = fmul float %image_load_48, %weight_load_3
  %tmp_11_9_0_3 = fadd float %tmp_11_9_0_2, %tmp_10_9_0_3
  %tmp_10_9_1 = fmul float %image_load_37, %weight_load_4
  %tmp_11_9_1 = fadd float %tmp_11_9_0_3, %tmp_10_9_1
  %tmp_10_9_1_1 = fmul float %image_load_41, %weight_load_5
  %tmp_11_9_1_1 = fadd float %tmp_11_9_1, %tmp_10_9_1_1
  %tmp_10_9_1_2 = fmul float %image_load_45, %weight_load_6
  %tmp_11_9_1_2 = fadd float %tmp_11_9_1_1, %tmp_10_9_1_2
  %image_load_49 = load float* %image_addr_49, align 4
  %tmp_10_9_1_3 = fmul float %image_load_49, %weight_load_7
  %tmp_11_9_1_3 = fadd float %tmp_11_9_1_2, %tmp_10_9_1_3
  %tmp_10_9_2 = fmul float %image_load_38, %weight_load_8
  %tmp_11_9_2 = fadd float %tmp_11_9_1_3, %tmp_10_9_2
  %tmp_10_9_2_1 = fmul float %image_load_42, %weight_load_9
  %tmp_11_9_2_1 = fadd float %tmp_11_9_2, %tmp_10_9_2_1
  %tmp_10_9_2_2 = fmul float %image_load_46, %weight_load_10
  %tmp_11_9_2_2 = fadd float %tmp_11_9_2_1, %tmp_10_9_2_2
  %image_load_50 = load float* %image_addr_50, align 4
  %tmp_10_9_2_3 = fmul float %image_load_50, %weight_load_11
  %tmp_11_9_2_3 = fadd float %tmp_11_9_2_2, %tmp_10_9_2_3
  %tmp_10_9_3 = fmul float %image_load_39, %weight_load_12
  %tmp_11_9_3 = fadd float %tmp_11_9_2_3, %tmp_10_9_3
  %tmp_10_9_3_1 = fmul float %image_load_43, %weight_load_13
  %tmp_11_9_3_1 = fadd float %tmp_11_9_3, %tmp_10_9_3_1
  %tmp_10_9_3_2 = fmul float %image_load_47, %weight_load_14
  %tmp_11_9_3_2 = fadd float %tmp_11_9_3_1, %tmp_10_9_3_2
  %image_load_51 = load float* %image_addr_51, align 4
  %tmp_10_9_3_3 = fmul float %image_load_51, %weight_load_15
  %tmp_11_9_3_3 = fadd float %tmp_11_9_3_2, %tmp_10_9_3_3
  %a_assign_17 = fadd float %tmp_11_9_3_3, %bias_load
  %a_assign_18_to_int = bitcast float %a_assign_17 to i32
  %tmp_49 = call i8 @_ssdm_op_PartSelect.i8.i32.i32.i32(i32 %a_assign_18_to_int, i32 23, i32 30)
  %tmp_455 = trunc i32 %a_assign_18_to_int to i23
  %notlhs9 = icmp ne i8 %tmp_49, -1
  %notrhs9 = icmp eq i23 %tmp_455, 0
  %tmp_51 = or i1 %notrhs9, %notlhs9
  %tmp_52 = fcmp ogt float %a_assign_17, 0.000000e+00
  %tmp_53 = and i1 %tmp_51, %tmp_52
  %a_assign_18 = select i1 %tmp_53, float %a_assign_17, float 0.000000e+00
  store float %a_assign_18, float* %output_addr_9, align 4
  %tmp_10_s = fmul float %image_load_40, %weight_load
  %tmp_11_s = fadd float %tmp_10_s, 0.000000e+00
  %tmp_10_10_0_1 = fmul float %image_load_44, %weight_load_1
  %tmp_11_10_0_1 = fadd float %tmp_11_s, %tmp_10_10_0_1
  %tmp_10_10_0_2 = fmul float %image_load_48, %weight_load_2
  %tmp_11_10_0_2 = fadd float %tmp_11_10_0_1, %tmp_10_10_0_2
  %image_load_52 = load float* %image_addr_52, align 4
  %tmp_10_10_0_3 = fmul float %image_load_52, %weight_load_3
  %tmp_11_10_0_3 = fadd float %tmp_11_10_0_2, %tmp_10_10_0_3
  %tmp_10_10_1 = fmul float %image_load_41, %weight_load_4
  %tmp_11_10_1 = fadd float %tmp_11_10_0_3, %tmp_10_10_1
  %tmp_10_10_1_1 = fmul float %image_load_45, %weight_load_5
  %tmp_11_10_1_1 = fadd float %tmp_11_10_1, %tmp_10_10_1_1
  %tmp_10_10_1_2 = fmul float %image_load_49, %weight_load_6
  %tmp_11_10_1_2 = fadd float %tmp_11_10_1_1, %tmp_10_10_1_2
  %image_load_53 = load float* %image_addr_53, align 4
  %tmp_10_10_1_3 = fmul float %image_load_53, %weight_load_7
  %tmp_11_10_1_3 = fadd float %tmp_11_10_1_2, %tmp_10_10_1_3
  %tmp_10_10_2 = fmul float %image_load_42, %weight_load_8
  %tmp_11_10_2 = fadd float %tmp_11_10_1_3, %tmp_10_10_2
  %tmp_10_10_2_1 = fmul float %image_load_46, %weight_load_9
  %tmp_11_10_2_1 = fadd float %tmp_11_10_2, %tmp_10_10_2_1
  %tmp_10_10_2_2 = fmul float %image_load_50, %weight_load_10
  %tmp_11_10_2_2 = fadd float %tmp_11_10_2_1, %tmp_10_10_2_2
  %image_load_54 = load float* %image_addr_54, align 4
  %tmp_10_10_2_3 = fmul float %image_load_54, %weight_load_11
  %tmp_11_10_2_3 = fadd float %tmp_11_10_2_2, %tmp_10_10_2_3
  %tmp_10_10_3 = fmul float %image_load_43, %weight_load_12
  %tmp_11_10_3 = fadd float %tmp_11_10_2_3, %tmp_10_10_3
  %tmp_10_10_3_1 = fmul float %image_load_47, %weight_load_13
  %tmp_11_10_3_1 = fadd float %tmp_11_10_3, %tmp_10_10_3_1
  %tmp_10_10_3_2 = fmul float %image_load_51, %weight_load_14
  %tmp_11_10_3_2 = fadd float %tmp_11_10_3_1, %tmp_10_10_3_2
  %image_load_55 = load float* %image_addr_55, align 4
  %tmp_10_10_3_3 = fmul float %image_load_55, %weight_load_15
  %tmp_11_10_3_3 = fadd float %tmp_11_10_3_2, %tmp_10_10_3_3
  %a_assign_19 = fadd float %tmp_11_10_3_3, %bias_load
  %a_assign_20_to_int = bitcast float %a_assign_19 to i32
  %tmp_54 = call i8 @_ssdm_op_PartSelect.i8.i32.i32.i32(i32 %a_assign_20_to_int, i32 23, i32 30)
  %tmp_456 = trunc i32 %a_assign_20_to_int to i23
  %notlhs10 = icmp ne i8 %tmp_54, -1
  %notrhs10 = icmp eq i23 %tmp_456, 0
  %tmp_56 = or i1 %notrhs10, %notlhs10
  %tmp_57 = fcmp ogt float %a_assign_19, 0.000000e+00
  %tmp_58 = and i1 %tmp_56, %tmp_57
  %a_assign_20 = select i1 %tmp_58, float %a_assign_19, float 0.000000e+00
  store float %a_assign_20, float* %output_addr_10, align 4
  %tmp_10_10 = fmul float %image_load_44, %weight_load
  %tmp_11_10 = fadd float %tmp_10_10, 0.000000e+00
  %tmp_10_11_0_1 = fmul float %image_load_48, %weight_load_1
  %tmp_11_11_0_1 = fadd float %tmp_11_10, %tmp_10_11_0_1
  %tmp_10_11_0_2 = fmul float %image_load_52, %weight_load_2
  %tmp_11_11_0_2 = fadd float %tmp_11_11_0_1, %tmp_10_11_0_2
  %image_load_56 = load float* %image_addr_56, align 4
  %tmp_10_11_0_3 = fmul float %image_load_56, %weight_load_3
  %tmp_11_11_0_3 = fadd float %tmp_11_11_0_2, %tmp_10_11_0_3
  %tmp_10_11_1 = fmul float %image_load_45, %weight_load_4
  %tmp_11_11_1 = fadd float %tmp_11_11_0_3, %tmp_10_11_1
  %tmp_10_11_1_1 = fmul float %image_load_49, %weight_load_5
  %tmp_11_11_1_1 = fadd float %tmp_11_11_1, %tmp_10_11_1_1
  %tmp_10_11_1_2 = fmul float %image_load_53, %weight_load_6
  %tmp_11_11_1_2 = fadd float %tmp_11_11_1_1, %tmp_10_11_1_2
  %image_load_57 = load float* %image_addr_57, align 4
  %tmp_10_11_1_3 = fmul float %image_load_57, %weight_load_7
  %tmp_11_11_1_3 = fadd float %tmp_11_11_1_2, %tmp_10_11_1_3
  %tmp_10_11_2 = fmul float %image_load_46, %weight_load_8
  %tmp_11_11_2 = fadd float %tmp_11_11_1_3, %tmp_10_11_2
  %tmp_10_11_2_1 = fmul float %image_load_50, %weight_load_9
  %tmp_11_11_2_1 = fadd float %tmp_11_11_2, %tmp_10_11_2_1
  %tmp_10_11_2_2 = fmul float %image_load_54, %weight_load_10
  %tmp_11_11_2_2 = fadd float %tmp_11_11_2_1, %tmp_10_11_2_2
  %image_load_58 = load float* %image_addr_58, align 4
  %tmp_10_11_2_3 = fmul float %image_load_58, %weight_load_11
  %tmp_11_11_2_3 = fadd float %tmp_11_11_2_2, %tmp_10_11_2_3
  %tmp_10_11_3 = fmul float %image_load_47, %weight_load_12
  %tmp_11_11_3 = fadd float %tmp_11_11_2_3, %tmp_10_11_3
  %tmp_10_11_3_1 = fmul float %image_load_51, %weight_load_13
  %tmp_11_11_3_1 = fadd float %tmp_11_11_3, %tmp_10_11_3_1
  %tmp_10_11_3_2 = fmul float %image_load_55, %weight_load_14
  %tmp_11_11_3_2 = fadd float %tmp_11_11_3_1, %tmp_10_11_3_2
  %image_load_59 = load float* %image_addr_59, align 4
  %tmp_10_11_3_3 = fmul float %image_load_59, %weight_load_15
  %tmp_11_11_3_3 = fadd float %tmp_11_11_3_2, %tmp_10_11_3_3
  %a_assign_21 = fadd float %tmp_11_11_3_3, %bias_load
  %a_assign_22_to_int = bitcast float %a_assign_21 to i32
  %tmp_59 = call i8 @_ssdm_op_PartSelect.i8.i32.i32.i32(i32 %a_assign_22_to_int, i32 23, i32 30)
  %tmp_457 = trunc i32 %a_assign_22_to_int to i23
  %notlhs11 = icmp ne i8 %tmp_59, -1
  %notrhs11 = icmp eq i23 %tmp_457, 0
  %tmp_61 = or i1 %notrhs11, %notlhs11
  %tmp_62 = fcmp ogt float %a_assign_21, 0.000000e+00
  %tmp_63 = and i1 %tmp_61, %tmp_62
  %a_assign_22 = select i1 %tmp_63, float %a_assign_21, float 0.000000e+00
  store float %a_assign_22, float* %output_addr_11, align 4
  %tmp_10_11 = fmul float %image_load_48, %weight_load
  %tmp_11_11 = fadd float %tmp_10_11, 0.000000e+00
  %tmp_10_12_0_1 = fmul float %image_load_52, %weight_load_1
  %tmp_11_12_0_1 = fadd float %tmp_11_11, %tmp_10_12_0_1
  %tmp_10_12_0_2 = fmul float %image_load_56, %weight_load_2
  %tmp_11_12_0_2 = fadd float %tmp_11_12_0_1, %tmp_10_12_0_2
  %image_load_60 = load float* %image_addr_60, align 4
  %tmp_10_12_0_3 = fmul float %image_load_60, %weight_load_3
  %tmp_11_12_0_3 = fadd float %tmp_11_12_0_2, %tmp_10_12_0_3
  %tmp_10_12_1 = fmul float %image_load_49, %weight_load_4
  %tmp_11_12_1 = fadd float %tmp_11_12_0_3, %tmp_10_12_1
  %tmp_10_12_1_1 = fmul float %image_load_53, %weight_load_5
  %tmp_11_12_1_1 = fadd float %tmp_11_12_1, %tmp_10_12_1_1
  %tmp_10_12_1_2 = fmul float %image_load_57, %weight_load_6
  %tmp_11_12_1_2 = fadd float %tmp_11_12_1_1, %tmp_10_12_1_2
  %image_load_61 = load float* %image_addr_61, align 4
  %tmp_10_12_1_3 = fmul float %image_load_61, %weight_load_7
  %tmp_11_12_1_3 = fadd float %tmp_11_12_1_2, %tmp_10_12_1_3
  %tmp_10_12_2 = fmul float %image_load_50, %weight_load_8
  %tmp_11_12_2 = fadd float %tmp_11_12_1_3, %tmp_10_12_2
  %tmp_10_12_2_1 = fmul float %image_load_54, %weight_load_9
  %tmp_11_12_2_1 = fadd float %tmp_11_12_2, %tmp_10_12_2_1
  %tmp_10_12_2_2 = fmul float %image_load_58, %weight_load_10
  %tmp_11_12_2_2 = fadd float %tmp_11_12_2_1, %tmp_10_12_2_2
  %image_load_62 = load float* %image_addr_62, align 4
  %tmp_10_12_2_3 = fmul float %image_load_62, %weight_load_11
  %tmp_11_12_2_3 = fadd float %tmp_11_12_2_2, %tmp_10_12_2_3
  %tmp_10_12_3 = fmul float %image_load_51, %weight_load_12
  %tmp_11_12_3 = fadd float %tmp_11_12_2_3, %tmp_10_12_3
  %tmp_10_12_3_1 = fmul float %image_load_55, %weight_load_13
  %tmp_11_12_3_1 = fadd float %tmp_11_12_3, %tmp_10_12_3_1
  %tmp_10_12_3_2 = fmul float %image_load_59, %weight_load_14
  %tmp_11_12_3_2 = fadd float %tmp_11_12_3_1, %tmp_10_12_3_2
  %image_load_63 = load float* %image_addr_63, align 4
  %tmp_10_12_3_3 = fmul float %image_load_63, %weight_load_15
  %tmp_11_12_3_3 = fadd float %tmp_11_12_3_2, %tmp_10_12_3_3
  %a_assign_23 = fadd float %tmp_11_12_3_3, %bias_load
  %a_assign_24_to_int = bitcast float %a_assign_23 to i32
  %tmp_64 = call i8 @_ssdm_op_PartSelect.i8.i32.i32.i32(i32 %a_assign_24_to_int, i32 23, i32 30)
  %tmp_458 = trunc i32 %a_assign_24_to_int to i23
  %notlhs12 = icmp ne i8 %tmp_64, -1
  %notrhs12 = icmp eq i23 %tmp_458, 0
  %tmp_66 = or i1 %notrhs12, %notlhs12
  %tmp_67 = fcmp ogt float %a_assign_23, 0.000000e+00
  %tmp_68 = and i1 %tmp_66, %tmp_67
  %a_assign_24 = select i1 %tmp_68, float %a_assign_23, float 0.000000e+00
  store float %a_assign_24, float* %output_addr_12, align 4
  %tmp_10_12 = fmul float %image_load_52, %weight_load
  %tmp_11_12 = fadd float %tmp_10_12, 0.000000e+00
  %tmp_10_13_0_1 = fmul float %image_load_56, %weight_load_1
  %tmp_11_13_0_1 = fadd float %tmp_11_12, %tmp_10_13_0_1
  %tmp_10_13_0_2 = fmul float %image_load_60, %weight_load_2
  %tmp_11_13_0_2 = fadd float %tmp_11_13_0_1, %tmp_10_13_0_2
  %image_load_64 = load float* %image_addr_64, align 4
  %tmp_10_13_0_3 = fmul float %image_load_64, %weight_load_3
  %tmp_11_13_0_3 = fadd float %tmp_11_13_0_2, %tmp_10_13_0_3
  %tmp_10_13_1 = fmul float %image_load_53, %weight_load_4
  %tmp_11_13_1 = fadd float %tmp_11_13_0_3, %tmp_10_13_1
  %tmp_10_13_1_1 = fmul float %image_load_57, %weight_load_5
  %tmp_11_13_1_1 = fadd float %tmp_11_13_1, %tmp_10_13_1_1
  %tmp_10_13_1_2 = fmul float %image_load_61, %weight_load_6
  %tmp_11_13_1_2 = fadd float %tmp_11_13_1_1, %tmp_10_13_1_2
  %image_load_65 = load float* %image_addr_65, align 4
  %tmp_10_13_1_3 = fmul float %image_load_65, %weight_load_7
  %tmp_11_13_1_3 = fadd float %tmp_11_13_1_2, %tmp_10_13_1_3
  %tmp_10_13_2 = fmul float %image_load_54, %weight_load_8
  %tmp_11_13_2 = fadd float %tmp_11_13_1_3, %tmp_10_13_2
  %tmp_10_13_2_1 = fmul float %image_load_58, %weight_load_9
  %tmp_11_13_2_1 = fadd float %tmp_11_13_2, %tmp_10_13_2_1
  %tmp_10_13_2_2 = fmul float %image_load_62, %weight_load_10
  %tmp_11_13_2_2 = fadd float %tmp_11_13_2_1, %tmp_10_13_2_2
  %image_load_66 = load float* %image_addr_66, align 4
  %tmp_10_13_2_3 = fmul float %image_load_66, %weight_load_11
  %tmp_11_13_2_3 = fadd float %tmp_11_13_2_2, %tmp_10_13_2_3
  %tmp_10_13_3 = fmul float %image_load_55, %weight_load_12
  %tmp_11_13_3 = fadd float %tmp_11_13_2_3, %tmp_10_13_3
  %tmp_10_13_3_1 = fmul float %image_load_59, %weight_load_13
  %tmp_11_13_3_1 = fadd float %tmp_11_13_3, %tmp_10_13_3_1
  %tmp_10_13_3_2 = fmul float %image_load_63, %weight_load_14
  %tmp_11_13_3_2 = fadd float %tmp_11_13_3_1, %tmp_10_13_3_2
  %image_load_67 = load float* %image_addr_67, align 4
  %tmp_10_13_3_3 = fmul float %image_load_67, %weight_load_15
  %tmp_11_13_3_3 = fadd float %tmp_11_13_3_2, %tmp_10_13_3_3
  %a_assign_25 = fadd float %tmp_11_13_3_3, %bias_load
  %a_assign_26_to_int = bitcast float %a_assign_25 to i32
  %tmp_69 = call i8 @_ssdm_op_PartSelect.i8.i32.i32.i32(i32 %a_assign_26_to_int, i32 23, i32 30)
  %tmp_459 = trunc i32 %a_assign_26_to_int to i23
  %notlhs13 = icmp ne i8 %tmp_69, -1
  %notrhs13 = icmp eq i23 %tmp_459, 0
  %tmp_71 = or i1 %notrhs13, %notlhs13
  %tmp_72 = fcmp ogt float %a_assign_25, 0.000000e+00
  %tmp_73 = and i1 %tmp_71, %tmp_72
  %a_assign_26 = select i1 %tmp_73, float %a_assign_25, float 0.000000e+00
  store float %a_assign_26, float* %output_addr_13, align 4
  %tmp_10_13 = fmul float %image_load_56, %weight_load
  %tmp_11_13 = fadd float %tmp_10_13, 0.000000e+00
  %tmp_10_14_0_1 = fmul float %image_load_60, %weight_load_1
  %tmp_11_14_0_1 = fadd float %tmp_11_13, %tmp_10_14_0_1
  %tmp_10_14_0_2 = fmul float %image_load_64, %weight_load_2
  %tmp_11_14_0_2 = fadd float %tmp_11_14_0_1, %tmp_10_14_0_2
  %image_load_68 = load float* %image_addr_68, align 4
  %tmp_10_14_0_3 = fmul float %image_load_68, %weight_load_3
  %tmp_11_14_0_3 = fadd float %tmp_11_14_0_2, %tmp_10_14_0_3
  %tmp_10_14_1 = fmul float %image_load_57, %weight_load_4
  %tmp_11_14_1 = fadd float %tmp_11_14_0_3, %tmp_10_14_1
  %tmp_10_14_1_1 = fmul float %image_load_61, %weight_load_5
  %tmp_11_14_1_1 = fadd float %tmp_11_14_1, %tmp_10_14_1_1
  %tmp_10_14_1_2 = fmul float %image_load_65, %weight_load_6
  %tmp_11_14_1_2 = fadd float %tmp_11_14_1_1, %tmp_10_14_1_2
  %image_load_69 = load float* %image_addr_69, align 4
  %tmp_10_14_1_3 = fmul float %image_load_69, %weight_load_7
  %tmp_11_14_1_3 = fadd float %tmp_11_14_1_2, %tmp_10_14_1_3
  %tmp_10_14_2 = fmul float %image_load_58, %weight_load_8
  %tmp_11_14_2 = fadd float %tmp_11_14_1_3, %tmp_10_14_2
  %tmp_10_14_2_1 = fmul float %image_load_62, %weight_load_9
  %tmp_11_14_2_1 = fadd float %tmp_11_14_2, %tmp_10_14_2_1
  %tmp_10_14_2_2 = fmul float %image_load_66, %weight_load_10
  %tmp_11_14_2_2 = fadd float %tmp_11_14_2_1, %tmp_10_14_2_2
  %image_load_70 = load float* %image_addr_70, align 4
  %tmp_10_14_2_3 = fmul float %image_load_70, %weight_load_11
  %tmp_11_14_2_3 = fadd float %tmp_11_14_2_2, %tmp_10_14_2_3
  %tmp_10_14_3 = fmul float %image_load_59, %weight_load_12
  %tmp_11_14_3 = fadd float %tmp_11_14_2_3, %tmp_10_14_3
  %tmp_10_14_3_1 = fmul float %image_load_63, %weight_load_13
  %tmp_11_14_3_1 = fadd float %tmp_11_14_3, %tmp_10_14_3_1
  %tmp_10_14_3_2 = fmul float %image_load_67, %weight_load_14
  %tmp_11_14_3_2 = fadd float %tmp_11_14_3_1, %tmp_10_14_3_2
  %image_load_71 = load float* %image_addr_71, align 4
  %tmp_10_14_3_3 = fmul float %image_load_71, %weight_load_15
  %tmp_11_14_3_3 = fadd float %tmp_11_14_3_2, %tmp_10_14_3_3
  %a_assign_27 = fadd float %tmp_11_14_3_3, %bias_load
  %a_assign_28_to_int = bitcast float %a_assign_27 to i32
  %tmp_74 = call i8 @_ssdm_op_PartSelect.i8.i32.i32.i32(i32 %a_assign_28_to_int, i32 23, i32 30)
  %tmp_460 = trunc i32 %a_assign_28_to_int to i23
  %notlhs14 = icmp ne i8 %tmp_74, -1
  %notrhs14 = icmp eq i23 %tmp_460, 0
  %tmp_76 = or i1 %notrhs14, %notlhs14
  %tmp_77 = fcmp ogt float %a_assign_27, 0.000000e+00
  %tmp_78 = and i1 %tmp_76, %tmp_77
  %a_assign_28 = select i1 %tmp_78, float %a_assign_27, float 0.000000e+00
  store float %a_assign_28, float* %output_addr_14, align 4
  %tmp_10_14 = fmul float %image_load_60, %weight_load
  %tmp_11_14 = fadd float %tmp_10_14, 0.000000e+00
  %tmp_10_15_0_1 = fmul float %image_load_64, %weight_load_1
  %tmp_11_15_0_1 = fadd float %tmp_11_14, %tmp_10_15_0_1
  %tmp_10_15_0_2 = fmul float %image_load_68, %weight_load_2
  %tmp_11_15_0_2 = fadd float %tmp_11_15_0_1, %tmp_10_15_0_2
  %image_load_72 = load float* %image_addr_72, align 4
  %tmp_10_15_0_3 = fmul float %image_load_72, %weight_load_3
  %tmp_11_15_0_3 = fadd float %tmp_11_15_0_2, %tmp_10_15_0_3
  %tmp_10_15_1 = fmul float %image_load_61, %weight_load_4
  %tmp_11_15_1 = fadd float %tmp_11_15_0_3, %tmp_10_15_1
  %tmp_10_15_1_1 = fmul float %image_load_65, %weight_load_5
  %tmp_11_15_1_1 = fadd float %tmp_11_15_1, %tmp_10_15_1_1
  %tmp_10_15_1_2 = fmul float %image_load_69, %weight_load_6
  %tmp_11_15_1_2 = fadd float %tmp_11_15_1_1, %tmp_10_15_1_2
  %image_load_73 = load float* %image_addr_73, align 4
  %tmp_10_15_1_3 = fmul float %image_load_73, %weight_load_7
  %tmp_11_15_1_3 = fadd float %tmp_11_15_1_2, %tmp_10_15_1_3
  %tmp_10_15_2 = fmul float %image_load_62, %weight_load_8
  %tmp_11_15_2 = fadd float %tmp_11_15_1_3, %tmp_10_15_2
  %tmp_10_15_2_1 = fmul float %image_load_66, %weight_load_9
  %tmp_11_15_2_1 = fadd float %tmp_11_15_2, %tmp_10_15_2_1
  %tmp_10_15_2_2 = fmul float %image_load_70, %weight_load_10
  %tmp_11_15_2_2 = fadd float %tmp_11_15_2_1, %tmp_10_15_2_2
  %image_load_74 = load float* %image_addr_74, align 4
  %tmp_10_15_2_3 = fmul float %image_load_74, %weight_load_11
  %tmp_11_15_2_3 = fadd float %tmp_11_15_2_2, %tmp_10_15_2_3
  %tmp_10_15_3 = fmul float %image_load_63, %weight_load_12
  %tmp_11_15_3 = fadd float %tmp_11_15_2_3, %tmp_10_15_3
  %tmp_10_15_3_1 = fmul float %image_load_67, %weight_load_13
  %tmp_11_15_3_1 = fadd float %tmp_11_15_3, %tmp_10_15_3_1
  %tmp_10_15_3_2 = fmul float %image_load_71, %weight_load_14
  %tmp_11_15_3_2 = fadd float %tmp_11_15_3_1, %tmp_10_15_3_2
  %image_load_75 = load float* %image_addr_75, align 4
  %tmp_10_15_3_3 = fmul float %image_load_75, %weight_load_15
  %tmp_11_15_3_3 = fadd float %tmp_11_15_3_2, %tmp_10_15_3_3
  %a_assign_29 = fadd float %tmp_11_15_3_3, %bias_load
  %a_assign_30_to_int = bitcast float %a_assign_29 to i32
  %tmp_79 = call i8 @_ssdm_op_PartSelect.i8.i32.i32.i32(i32 %a_assign_30_to_int, i32 23, i32 30)
  %tmp_461 = trunc i32 %a_assign_30_to_int to i23
  %notlhs15 = icmp ne i8 %tmp_79, -1
  %notrhs15 = icmp eq i23 %tmp_461, 0
  %tmp_81 = or i1 %notrhs15, %notlhs15
  %tmp_82 = fcmp ogt float %a_assign_29, 0.000000e+00
  %tmp_83 = and i1 %tmp_81, %tmp_82
  %a_assign_30 = select i1 %tmp_83, float %a_assign_29, float 0.000000e+00
  store float %a_assign_30, float* %output_addr_15, align 4
  %tmp_10_15 = fmul float %image_load_64, %weight_load
  %tmp_11_15 = fadd float %tmp_10_15, 0.000000e+00
  %tmp_10_16_0_1 = fmul float %image_load_68, %weight_load_1
  %tmp_11_16_0_1 = fadd float %tmp_11_15, %tmp_10_16_0_1
  %tmp_10_16_0_2 = fmul float %image_load_72, %weight_load_2
  %tmp_11_16_0_2 = fadd float %tmp_11_16_0_1, %tmp_10_16_0_2
  %image_load_76 = load float* %image_addr_76, align 4
  %tmp_10_16_0_3 = fmul float %image_load_76, %weight_load_3
  %tmp_11_16_0_3 = fadd float %tmp_11_16_0_2, %tmp_10_16_0_3
  %tmp_10_16_1 = fmul float %image_load_65, %weight_load_4
  %tmp_11_16_1 = fadd float %tmp_11_16_0_3, %tmp_10_16_1
  %tmp_10_16_1_1 = fmul float %image_load_69, %weight_load_5
  %tmp_11_16_1_1 = fadd float %tmp_11_16_1, %tmp_10_16_1_1
  %tmp_10_16_1_2 = fmul float %image_load_73, %weight_load_6
  %tmp_11_16_1_2 = fadd float %tmp_11_16_1_1, %tmp_10_16_1_2
  %image_load_77 = load float* %image_addr_77, align 4
  %tmp_10_16_1_3 = fmul float %image_load_77, %weight_load_7
  %tmp_11_16_1_3 = fadd float %tmp_11_16_1_2, %tmp_10_16_1_3
  %tmp_10_16_2 = fmul float %image_load_66, %weight_load_8
  %tmp_11_16_2 = fadd float %tmp_11_16_1_3, %tmp_10_16_2
  %tmp_10_16_2_1 = fmul float %image_load_70, %weight_load_9
  %tmp_11_16_2_1 = fadd float %tmp_11_16_2, %tmp_10_16_2_1
  %tmp_10_16_2_2 = fmul float %image_load_74, %weight_load_10
  %tmp_11_16_2_2 = fadd float %tmp_11_16_2_1, %tmp_10_16_2_2
  %image_load_78 = load float* %image_addr_78, align 4
  %tmp_10_16_2_3 = fmul float %image_load_78, %weight_load_11
  %tmp_11_16_2_3 = fadd float %tmp_11_16_2_2, %tmp_10_16_2_3
  %tmp_10_16_3 = fmul float %image_load_67, %weight_load_12
  %tmp_11_16_3 = fadd float %tmp_11_16_2_3, %tmp_10_16_3
  %tmp_10_16_3_1 = fmul float %image_load_71, %weight_load_13
  %tmp_11_16_3_1 = fadd float %tmp_11_16_3, %tmp_10_16_3_1
  %tmp_10_16_3_2 = fmul float %image_load_75, %weight_load_14
  %tmp_11_16_3_2 = fadd float %tmp_11_16_3_1, %tmp_10_16_3_2
  %image_load_79 = load float* %image_addr_79, align 4
  %tmp_10_16_3_3 = fmul float %image_load_79, %weight_load_15
  %tmp_11_16_3_3 = fadd float %tmp_11_16_3_2, %tmp_10_16_3_3
  %a_assign_31 = fadd float %tmp_11_16_3_3, %bias_load
  %a_assign_32_to_int = bitcast float %a_assign_31 to i32
  %tmp_84 = call i8 @_ssdm_op_PartSelect.i8.i32.i32.i32(i32 %a_assign_32_to_int, i32 23, i32 30)
  %tmp_462 = trunc i32 %a_assign_32_to_int to i23
  %notlhs16 = icmp ne i8 %tmp_84, -1
  %notrhs16 = icmp eq i23 %tmp_462, 0
  %tmp_86 = or i1 %notrhs16, %notlhs16
  %tmp_87 = fcmp ogt float %a_assign_31, 0.000000e+00
  %tmp_88 = and i1 %tmp_86, %tmp_87
  %a_assign_32 = select i1 %tmp_88, float %a_assign_31, float 0.000000e+00
  store float %a_assign_32, float* %output_addr_16, align 4
  %tmp_10_16 = fmul float %image_load_68, %weight_load
  %tmp_11_16 = fadd float %tmp_10_16, 0.000000e+00
  %tmp_10_17_0_1 = fmul float %image_load_72, %weight_load_1
  %tmp_11_17_0_1 = fadd float %tmp_11_16, %tmp_10_17_0_1
  %tmp_10_17_0_2 = fmul float %image_load_76, %weight_load_2
  %tmp_11_17_0_2 = fadd float %tmp_11_17_0_1, %tmp_10_17_0_2
  %image_load_80 = load float* %image_addr_80, align 4
  %tmp_10_17_0_3 = fmul float %image_load_80, %weight_load_3
  %tmp_11_17_0_3 = fadd float %tmp_11_17_0_2, %tmp_10_17_0_3
  %tmp_10_17_1 = fmul float %image_load_69, %weight_load_4
  %tmp_11_17_1 = fadd float %tmp_11_17_0_3, %tmp_10_17_1
  %tmp_10_17_1_1 = fmul float %image_load_73, %weight_load_5
  %tmp_11_17_1_1 = fadd float %tmp_11_17_1, %tmp_10_17_1_1
  %tmp_10_17_1_2 = fmul float %image_load_77, %weight_load_6
  %tmp_11_17_1_2 = fadd float %tmp_11_17_1_1, %tmp_10_17_1_2
  %image_load_81 = load float* %image_addr_81, align 4
  %tmp_10_17_1_3 = fmul float %image_load_81, %weight_load_7
  %tmp_11_17_1_3 = fadd float %tmp_11_17_1_2, %tmp_10_17_1_3
  %tmp_10_17_2 = fmul float %image_load_70, %weight_load_8
  %tmp_11_17_2 = fadd float %tmp_11_17_1_3, %tmp_10_17_2
  %tmp_10_17_2_1 = fmul float %image_load_74, %weight_load_9
  %tmp_11_17_2_1 = fadd float %tmp_11_17_2, %tmp_10_17_2_1
  %tmp_10_17_2_2 = fmul float %image_load_78, %weight_load_10
  %tmp_11_17_2_2 = fadd float %tmp_11_17_2_1, %tmp_10_17_2_2
  %image_load_82 = load float* %image_addr_82, align 4
  %tmp_10_17_2_3 = fmul float %image_load_82, %weight_load_11
  %tmp_11_17_2_3 = fadd float %tmp_11_17_2_2, %tmp_10_17_2_3
  %tmp_10_17_3 = fmul float %image_load_71, %weight_load_12
  %tmp_11_17_3 = fadd float %tmp_11_17_2_3, %tmp_10_17_3
  %tmp_10_17_3_1 = fmul float %image_load_75, %weight_load_13
  %tmp_11_17_3_1 = fadd float %tmp_11_17_3, %tmp_10_17_3_1
  %tmp_10_17_3_2 = fmul float %image_load_79, %weight_load_14
  %tmp_11_17_3_2 = fadd float %tmp_11_17_3_1, %tmp_10_17_3_2
  %image_load_83 = load float* %image_addr_83, align 4
  %tmp_10_17_3_3 = fmul float %image_load_83, %weight_load_15
  %tmp_11_17_3_3 = fadd float %tmp_11_17_3_2, %tmp_10_17_3_3
  %a_assign_33 = fadd float %tmp_11_17_3_3, %bias_load
  %a_assign_34_to_int = bitcast float %a_assign_33 to i32
  %tmp_89 = call i8 @_ssdm_op_PartSelect.i8.i32.i32.i32(i32 %a_assign_34_to_int, i32 23, i32 30)
  %tmp_463 = trunc i32 %a_assign_34_to_int to i23
  %notlhs17 = icmp ne i8 %tmp_89, -1
  %notrhs17 = icmp eq i23 %tmp_463, 0
  %tmp_91 = or i1 %notrhs17, %notlhs17
  %tmp_92 = fcmp ogt float %a_assign_33, 0.000000e+00
  %tmp_93 = and i1 %tmp_91, %tmp_92
  %a_assign_34 = select i1 %tmp_93, float %a_assign_33, float 0.000000e+00
  store float %a_assign_34, float* %output_addr_17, align 4
  %tmp_10_17 = fmul float %image_load_72, %weight_load
  %tmp_11_17 = fadd float %tmp_10_17, 0.000000e+00
  %tmp_10_18_0_1 = fmul float %image_load_76, %weight_load_1
  %tmp_11_18_0_1 = fadd float %tmp_11_17, %tmp_10_18_0_1
  %tmp_10_18_0_2 = fmul float %image_load_80, %weight_load_2
  %tmp_11_18_0_2 = fadd float %tmp_11_18_0_1, %tmp_10_18_0_2
  %image_load_84 = load float* %image_addr_84, align 4
  %tmp_10_18_0_3 = fmul float %image_load_84, %weight_load_3
  %tmp_11_18_0_3 = fadd float %tmp_11_18_0_2, %tmp_10_18_0_3
  %tmp_10_18_1 = fmul float %image_load_73, %weight_load_4
  %tmp_11_18_1 = fadd float %tmp_11_18_0_3, %tmp_10_18_1
  %tmp_10_18_1_1 = fmul float %image_load_77, %weight_load_5
  %tmp_11_18_1_1 = fadd float %tmp_11_18_1, %tmp_10_18_1_1
  %tmp_10_18_1_2 = fmul float %image_load_81, %weight_load_6
  %tmp_11_18_1_2 = fadd float %tmp_11_18_1_1, %tmp_10_18_1_2
  %image_load_85 = load float* %image_addr_85, align 4
  %tmp_10_18_1_3 = fmul float %image_load_85, %weight_load_7
  %tmp_11_18_1_3 = fadd float %tmp_11_18_1_2, %tmp_10_18_1_3
  %tmp_10_18_2 = fmul float %image_load_74, %weight_load_8
  %tmp_11_18_2 = fadd float %tmp_11_18_1_3, %tmp_10_18_2
  %tmp_10_18_2_1 = fmul float %image_load_78, %weight_load_9
  %tmp_11_18_2_1 = fadd float %tmp_11_18_2, %tmp_10_18_2_1
  %tmp_10_18_2_2 = fmul float %image_load_82, %weight_load_10
  %tmp_11_18_2_2 = fadd float %tmp_11_18_2_1, %tmp_10_18_2_2
  %image_load_86 = load float* %image_addr_86, align 4
  %tmp_10_18_2_3 = fmul float %image_load_86, %weight_load_11
  %tmp_11_18_2_3 = fadd float %tmp_11_18_2_2, %tmp_10_18_2_3
  %tmp_10_18_3 = fmul float %image_load_75, %weight_load_12
  %tmp_11_18_3 = fadd float %tmp_11_18_2_3, %tmp_10_18_3
  %tmp_10_18_3_1 = fmul float %image_load_79, %weight_load_13
  %tmp_11_18_3_1 = fadd float %tmp_11_18_3, %tmp_10_18_3_1
  %tmp_10_18_3_2 = fmul float %image_load_83, %weight_load_14
  %tmp_11_18_3_2 = fadd float %tmp_11_18_3_1, %tmp_10_18_3_2
  %image_load_87 = load float* %image_addr_87, align 4
  %tmp_10_18_3_3 = fmul float %image_load_87, %weight_load_15
  %tmp_11_18_3_3 = fadd float %tmp_11_18_3_2, %tmp_10_18_3_3
  %a_assign_35 = fadd float %tmp_11_18_3_3, %bias_load
  %a_assign_36_to_int = bitcast float %a_assign_35 to i32
  %tmp_94 = call i8 @_ssdm_op_PartSelect.i8.i32.i32.i32(i32 %a_assign_36_to_int, i32 23, i32 30)
  %tmp_464 = trunc i32 %a_assign_36_to_int to i23
  %notlhs18 = icmp ne i8 %tmp_94, -1
  %notrhs18 = icmp eq i23 %tmp_464, 0
  %tmp_96 = or i1 %notrhs18, %notlhs18
  %tmp_97 = fcmp ogt float %a_assign_35, 0.000000e+00
  %tmp_98 = and i1 %tmp_96, %tmp_97
  %a_assign_36 = select i1 %tmp_98, float %a_assign_35, float 0.000000e+00
  store float %a_assign_36, float* %output_addr_18, align 4
  %tmp_10_18 = fmul float %image_load_76, %weight_load
  %tmp_11_18 = fadd float %tmp_10_18, 0.000000e+00
  %tmp_10_19_0_1 = fmul float %image_load_80, %weight_load_1
  %tmp_11_19_0_1 = fadd float %tmp_11_18, %tmp_10_19_0_1
  %tmp_10_19_0_2 = fmul float %image_load_84, %weight_load_2
  %tmp_11_19_0_2 = fadd float %tmp_11_19_0_1, %tmp_10_19_0_2
  %image_load_88 = load float* %image_addr_88, align 4
  %tmp_10_19_0_3 = fmul float %image_load_88, %weight_load_3
  %tmp_11_19_0_3 = fadd float %tmp_11_19_0_2, %tmp_10_19_0_3
  %tmp_10_19_1 = fmul float %image_load_77, %weight_load_4
  %tmp_11_19_1 = fadd float %tmp_11_19_0_3, %tmp_10_19_1
  %tmp_10_19_1_1 = fmul float %image_load_81, %weight_load_5
  %tmp_11_19_1_1 = fadd float %tmp_11_19_1, %tmp_10_19_1_1
  %tmp_10_19_1_2 = fmul float %image_load_85, %weight_load_6
  %tmp_11_19_1_2 = fadd float %tmp_11_19_1_1, %tmp_10_19_1_2
  %image_load_89 = load float* %image_addr_89, align 4
  %tmp_10_19_1_3 = fmul float %image_load_89, %weight_load_7
  %tmp_11_19_1_3 = fadd float %tmp_11_19_1_2, %tmp_10_19_1_3
  %tmp_10_19_2 = fmul float %image_load_78, %weight_load_8
  %tmp_11_19_2 = fadd float %tmp_11_19_1_3, %tmp_10_19_2
  %tmp_10_19_2_1 = fmul float %image_load_82, %weight_load_9
  %tmp_11_19_2_1 = fadd float %tmp_11_19_2, %tmp_10_19_2_1
  %tmp_10_19_2_2 = fmul float %image_load_86, %weight_load_10
  %tmp_11_19_2_2 = fadd float %tmp_11_19_2_1, %tmp_10_19_2_2
  %image_load_90 = load float* %image_addr_90, align 4
  %tmp_10_19_2_3 = fmul float %image_load_90, %weight_load_11
  %tmp_11_19_2_3 = fadd float %tmp_11_19_2_2, %tmp_10_19_2_3
  %tmp_10_19_3 = fmul float %image_load_79, %weight_load_12
  %tmp_11_19_3 = fadd float %tmp_11_19_2_3, %tmp_10_19_3
  %tmp_10_19_3_1 = fmul float %image_load_83, %weight_load_13
  %tmp_11_19_3_1 = fadd float %tmp_11_19_3, %tmp_10_19_3_1
  %tmp_10_19_3_2 = fmul float %image_load_87, %weight_load_14
  %tmp_11_19_3_2 = fadd float %tmp_11_19_3_1, %tmp_10_19_3_2
  %image_load_91 = load float* %image_addr_91, align 4
  %tmp_10_19_3_3 = fmul float %image_load_91, %weight_load_15
  %tmp_11_19_3_3 = fadd float %tmp_11_19_3_2, %tmp_10_19_3_3
  %a_assign_37 = fadd float %tmp_11_19_3_3, %bias_load
  %a_assign_38_to_int = bitcast float %a_assign_37 to i32
  %tmp_99 = call i8 @_ssdm_op_PartSelect.i8.i32.i32.i32(i32 %a_assign_38_to_int, i32 23, i32 30)
  %tmp_465 = trunc i32 %a_assign_38_to_int to i23
  %notlhs19 = icmp ne i8 %tmp_99, -1
  %notrhs19 = icmp eq i23 %tmp_465, 0
  %tmp_101 = or i1 %notrhs19, %notlhs19
  %tmp_102 = fcmp ogt float %a_assign_37, 0.000000e+00
  %tmp_103 = and i1 %tmp_101, %tmp_102
  %a_assign_38 = select i1 %tmp_103, float %a_assign_37, float 0.000000e+00
  store float %a_assign_38, float* %output_addr_19, align 4
  %tmp_10_19 = fmul float %image_load_80, %weight_load
  %tmp_11_19 = fadd float %tmp_10_19, 0.000000e+00
  %tmp_10_20_0_1 = fmul float %image_load_84, %weight_load_1
  %tmp_11_20_0_1 = fadd float %tmp_11_19, %tmp_10_20_0_1
  %tmp_10_20_0_2 = fmul float %image_load_88, %weight_load_2
  %tmp_11_20_0_2 = fadd float %tmp_11_20_0_1, %tmp_10_20_0_2
  %image_load_92 = load float* %image_addr_92, align 4
  %tmp_10_20_0_3 = fmul float %image_load_92, %weight_load_3
  %tmp_11_20_0_3 = fadd float %tmp_11_20_0_2, %tmp_10_20_0_3
  %tmp_10_20_1 = fmul float %image_load_81, %weight_load_4
  %tmp_11_20_1 = fadd float %tmp_11_20_0_3, %tmp_10_20_1
  %tmp_10_20_1_1 = fmul float %image_load_85, %weight_load_5
  %tmp_11_20_1_1 = fadd float %tmp_11_20_1, %tmp_10_20_1_1
  %tmp_10_20_1_2 = fmul float %image_load_89, %weight_load_6
  %tmp_11_20_1_2 = fadd float %tmp_11_20_1_1, %tmp_10_20_1_2
  %image_load_93 = load float* %image_addr_93, align 4
  %tmp_10_20_1_3 = fmul float %image_load_93, %weight_load_7
  %tmp_11_20_1_3 = fadd float %tmp_11_20_1_2, %tmp_10_20_1_3
  %tmp_10_20_2 = fmul float %image_load_82, %weight_load_8
  %tmp_11_20_2 = fadd float %tmp_11_20_1_3, %tmp_10_20_2
  %tmp_10_20_2_1 = fmul float %image_load_86, %weight_load_9
  %tmp_11_20_2_1 = fadd float %tmp_11_20_2, %tmp_10_20_2_1
  %tmp_10_20_2_2 = fmul float %image_load_90, %weight_load_10
  %tmp_11_20_2_2 = fadd float %tmp_11_20_2_1, %tmp_10_20_2_2
  %image_load_94 = load float* %image_addr_94, align 4
  %tmp_10_20_2_3 = fmul float %image_load_94, %weight_load_11
  %tmp_11_20_2_3 = fadd float %tmp_11_20_2_2, %tmp_10_20_2_3
  %tmp_10_20_3 = fmul float %image_load_83, %weight_load_12
  %tmp_11_20_3 = fadd float %tmp_11_20_2_3, %tmp_10_20_3
  %tmp_10_20_3_1 = fmul float %image_load_87, %weight_load_13
  %tmp_11_20_3_1 = fadd float %tmp_11_20_3, %tmp_10_20_3_1
  %tmp_10_20_3_2 = fmul float %image_load_91, %weight_load_14
  %tmp_11_20_3_2 = fadd float %tmp_11_20_3_1, %tmp_10_20_3_2
  %image_load_95 = load float* %image_addr_95, align 4
  %tmp_10_20_3_3 = fmul float %image_load_95, %weight_load_15
  %tmp_11_20_3_3 = fadd float %tmp_11_20_3_2, %tmp_10_20_3_3
  %a_assign_39 = fadd float %tmp_11_20_3_3, %bias_load
  %a_assign_40_to_int = bitcast float %a_assign_39 to i32
  %tmp_104 = call i8 @_ssdm_op_PartSelect.i8.i32.i32.i32(i32 %a_assign_40_to_int, i32 23, i32 30)
  %tmp_466 = trunc i32 %a_assign_40_to_int to i23
  %notlhs20 = icmp ne i8 %tmp_104, -1
  %notrhs20 = icmp eq i23 %tmp_466, 0
  %tmp_106 = or i1 %notrhs20, %notlhs20
  %tmp_107 = fcmp ogt float %a_assign_39, 0.000000e+00
  %tmp_108 = and i1 %tmp_106, %tmp_107
  %a_assign_40 = select i1 %tmp_108, float %a_assign_39, float 0.000000e+00
  store float %a_assign_40, float* %output_addr_20, align 4
  %tmp_10_20 = fmul float %image_load_84, %weight_load
  %tmp_11_20 = fadd float %tmp_10_20, 0.000000e+00
  %tmp_10_21_0_1 = fmul float %image_load_88, %weight_load_1
  %tmp_11_21_0_1 = fadd float %tmp_11_20, %tmp_10_21_0_1
  %tmp_10_21_0_2 = fmul float %image_load_92, %weight_load_2
  %tmp_11_21_0_2 = fadd float %tmp_11_21_0_1, %tmp_10_21_0_2
  %image_load_96 = load float* %image_addr_96, align 4
  %tmp_10_21_0_3 = fmul float %image_load_96, %weight_load_3
  %tmp_11_21_0_3 = fadd float %tmp_11_21_0_2, %tmp_10_21_0_3
  %tmp_10_21_1 = fmul float %image_load_85, %weight_load_4
  %tmp_11_21_1 = fadd float %tmp_11_21_0_3, %tmp_10_21_1
  %tmp_10_21_1_1 = fmul float %image_load_89, %weight_load_5
  %tmp_11_21_1_1 = fadd float %tmp_11_21_1, %tmp_10_21_1_1
  %tmp_10_21_1_2 = fmul float %image_load_93, %weight_load_6
  %tmp_11_21_1_2 = fadd float %tmp_11_21_1_1, %tmp_10_21_1_2
  %image_load_97 = load float* %image_addr_97, align 4
  %tmp_10_21_1_3 = fmul float %image_load_97, %weight_load_7
  %tmp_11_21_1_3 = fadd float %tmp_11_21_1_2, %tmp_10_21_1_3
  %tmp_10_21_2 = fmul float %image_load_86, %weight_load_8
  %tmp_11_21_2 = fadd float %tmp_11_21_1_3, %tmp_10_21_2
  %tmp_10_21_2_1 = fmul float %image_load_90, %weight_load_9
  %tmp_11_21_2_1 = fadd float %tmp_11_21_2, %tmp_10_21_2_1
  %tmp_10_21_2_2 = fmul float %image_load_94, %weight_load_10
  %tmp_11_21_2_2 = fadd float %tmp_11_21_2_1, %tmp_10_21_2_2
  %image_load_98 = load float* %image_addr_98, align 4
  %tmp_10_21_2_3 = fmul float %image_load_98, %weight_load_11
  %tmp_11_21_2_3 = fadd float %tmp_11_21_2_2, %tmp_10_21_2_3
  %tmp_10_21_3 = fmul float %image_load_87, %weight_load_12
  %tmp_11_21_3 = fadd float %tmp_11_21_2_3, %tmp_10_21_3
  %tmp_10_21_3_1 = fmul float %image_load_91, %weight_load_13
  %tmp_11_21_3_1 = fadd float %tmp_11_21_3, %tmp_10_21_3_1
  %tmp_10_21_3_2 = fmul float %image_load_95, %weight_load_14
  %tmp_11_21_3_2 = fadd float %tmp_11_21_3_1, %tmp_10_21_3_2
  %image_load_99 = load float* %image_addr_99, align 4
  %tmp_10_21_3_3 = fmul float %image_load_99, %weight_load_15
  %tmp_11_21_3_3 = fadd float %tmp_11_21_3_2, %tmp_10_21_3_3
  %a_assign_41 = fadd float %tmp_11_21_3_3, %bias_load
  %a_assign_42_to_int = bitcast float %a_assign_41 to i32
  %tmp_109 = call i8 @_ssdm_op_PartSelect.i8.i32.i32.i32(i32 %a_assign_42_to_int, i32 23, i32 30)
  %tmp_467 = trunc i32 %a_assign_42_to_int to i23
  %notlhs21 = icmp ne i8 %tmp_109, -1
  %notrhs21 = icmp eq i23 %tmp_467, 0
  %tmp_111 = or i1 %notrhs21, %notlhs21
  %tmp_112 = fcmp ogt float %a_assign_41, 0.000000e+00
  %tmp_113 = and i1 %tmp_111, %tmp_112
  %a_assign_42 = select i1 %tmp_113, float %a_assign_41, float 0.000000e+00
  store float %a_assign_42, float* %output_addr_21, align 4
  %weight_load_16 = load float* %weight_addr, align 4
  %tmp_10_21 = fmul float %image_load_88, %weight_load_16
  %tmp_11_21 = fadd float %tmp_10_21, 0.000000e+00
  %weight_load_17 = load float* %weight_addr_1, align 4
  %tmp_10_22_0_1 = fmul float %image_load_92, %weight_load_17
  %tmp_11_22_0_1 = fadd float %tmp_11_21, %tmp_10_22_0_1
  %weight_load_18 = load float* %weight_addr_2, align 4
  %tmp_10_22_0_2 = fmul float %image_load_96, %weight_load_18
  %tmp_11_22_0_2 = fadd float %tmp_11_22_0_1, %tmp_10_22_0_2
  %image_load_100 = load float* %image_addr_100, align 4
  %weight_load_19 = load float* %weight_addr_3, align 4
  %tmp_10_22_0_3 = fmul float %image_load_100, %weight_load_19
  %tmp_11_22_0_3 = fadd float %tmp_11_22_0_2, %tmp_10_22_0_3
  %weight_load_20 = load float* %weight_addr_4, align 4
  %tmp_10_22_1 = fmul float %image_load_89, %weight_load_20
  %tmp_11_22_1 = fadd float %tmp_11_22_0_3, %tmp_10_22_1
  %weight_load_21 = load float* %weight_addr_5, align 4
  %tmp_10_22_1_1 = fmul float %image_load_93, %weight_load_21
  %tmp_11_22_1_1 = fadd float %tmp_11_22_1, %tmp_10_22_1_1
  %weight_load_22 = load float* %weight_addr_6, align 4
  %tmp_10_22_1_2 = fmul float %image_load_97, %weight_load_22
  %tmp_11_22_1_2 = fadd float %tmp_11_22_1_1, %tmp_10_22_1_2
  %image_load_101 = load float* %image_addr_101, align 4
  %weight_load_23 = load float* %weight_addr_7, align 4
  %tmp_10_22_1_3 = fmul float %image_load_101, %weight_load_23
  %tmp_11_22_1_3 = fadd float %tmp_11_22_1_2, %tmp_10_22_1_3
  %weight_load_24 = load float* %weight_addr_8, align 4
  %tmp_10_22_2 = fmul float %image_load_90, %weight_load_24
  %tmp_11_22_2 = fadd float %tmp_11_22_1_3, %tmp_10_22_2
  %weight_load_25 = load float* %weight_addr_9, align 4
  %tmp_10_22_2_1 = fmul float %image_load_94, %weight_load_25
  %tmp_11_22_2_1 = fadd float %tmp_11_22_2, %tmp_10_22_2_1
  %tmp_10_22_2_2 = fmul float %image_load_98, %weight_load_10
  %tmp_11_22_2_2 = fadd float %tmp_11_22_2_1, %tmp_10_22_2_2
  %image_load_102 = load float* %image_addr_102, align 4
  %tmp_10_22_2_3 = fmul float %image_load_102, %weight_load_11
  %tmp_11_22_2_3 = fadd float %tmp_11_22_2_2, %tmp_10_22_2_3
  %tmp_10_22_3 = fmul float %image_load_91, %weight_load_12
  %tmp_11_22_3 = fadd float %tmp_11_22_2_3, %tmp_10_22_3
  %tmp_10_22_3_1 = fmul float %image_load_95, %weight_load_13
  %tmp_11_22_3_1 = fadd float %tmp_11_22_3, %tmp_10_22_3_1
  %tmp_10_22_3_2 = fmul float %image_load_99, %weight_load_14
  %tmp_11_22_3_2 = fadd float %tmp_11_22_3_1, %tmp_10_22_3_2
  %image_load_103 = load float* %image_addr_103, align 4
  %tmp_10_22_3_3 = fmul float %image_load_103, %weight_load_15
  %tmp_11_22_3_3 = fadd float %tmp_11_22_3_2, %tmp_10_22_3_3
  %a_assign_43 = fadd float %tmp_11_22_3_3, %bias_load
  %a_assign_44_to_int = bitcast float %a_assign_43 to i32
  %tmp_114 = call i8 @_ssdm_op_PartSelect.i8.i32.i32.i32(i32 %a_assign_44_to_int, i32 23, i32 30)
  %tmp_468 = trunc i32 %a_assign_44_to_int to i23
  %notlhs22 = icmp ne i8 %tmp_114, -1
  %notrhs22 = icmp eq i23 %tmp_468, 0
  %tmp_116 = or i1 %notrhs22, %notlhs22
  %tmp_117 = fcmp ogt float %a_assign_43, 0.000000e+00
  %tmp_118 = and i1 %tmp_116, %tmp_117
  %a_assign_44 = select i1 %tmp_118, float %a_assign_43, float 0.000000e+00
  store float %a_assign_44, float* %output_addr_22, align 4
  %tmp_10_22 = fmul float %image_load_92, %weight_load_16
  %tmp_11_22 = fadd float %tmp_10_22, 0.000000e+00
  %tmp_10_23_0_1 = fmul float %image_load_96, %weight_load_17
  %tmp_11_23_0_1 = fadd float %tmp_11_22, %tmp_10_23_0_1
  %tmp_10_23_0_2 = fmul float %image_load_100, %weight_load_18
  %tmp_11_23_0_2 = fadd float %tmp_11_23_0_1, %tmp_10_23_0_2
  %image_load_104 = load float* %image_addr_104, align 4
  %tmp_10_23_0_3 = fmul float %image_load_104, %weight_load_19
  %tmp_11_23_0_3 = fadd float %tmp_11_23_0_2, %tmp_10_23_0_3
  %tmp_10_23_1 = fmul float %image_load_93, %weight_load_20
  %tmp_11_23_1 = fadd float %tmp_11_23_0_3, %tmp_10_23_1
  %tmp_10_23_1_1 = fmul float %image_load_97, %weight_load_21
  %tmp_11_23_1_1 = fadd float %tmp_11_23_1, %tmp_10_23_1_1
  %tmp_10_23_1_2 = fmul float %image_load_101, %weight_load_22
  %tmp_11_23_1_2 = fadd float %tmp_11_23_1_1, %tmp_10_23_1_2
  %image_load_105 = load float* %image_addr_105, align 4
  %tmp_10_23_1_3 = fmul float %image_load_105, %weight_load_23
  %tmp_11_23_1_3 = fadd float %tmp_11_23_1_2, %tmp_10_23_1_3
  %tmp_10_23_2 = fmul float %image_load_94, %weight_load_24
  %tmp_11_23_2 = fadd float %tmp_11_23_1_3, %tmp_10_23_2
  %tmp_10_23_2_1 = fmul float %image_load_98, %weight_load_25
  %tmp_11_23_2_1 = fadd float %tmp_11_23_2, %tmp_10_23_2_1
  %weight_load_26 = load float* %weight_addr_10, align 4
  %tmp_10_23_2_2 = fmul float %image_load_102, %weight_load_26
  %tmp_11_23_2_2 = fadd float %tmp_11_23_2_1, %tmp_10_23_2_2
  %image_load_106 = load float* %image_addr_106, align 4
  %weight_load_27 = load float* %weight_addr_11, align 4
  %tmp_10_23_2_3 = fmul float %image_load_106, %weight_load_27
  %tmp_11_23_2_3 = fadd float %tmp_11_23_2_2, %tmp_10_23_2_3
  %weight_load_28 = load float* %weight_addr_12, align 4
  %tmp_10_23_3 = fmul float %image_load_95, %weight_load_28
  %tmp_11_23_3 = fadd float %tmp_11_23_2_3, %tmp_10_23_3
  %weight_load_29 = load float* %weight_addr_13, align 4
  %tmp_10_23_3_1 = fmul float %image_load_99, %weight_load_29
  %tmp_11_23_3_1 = fadd float %tmp_11_23_3, %tmp_10_23_3_1
  %weight_load_30 = load float* %weight_addr_14, align 4
  %tmp_10_23_3_2 = fmul float %image_load_103, %weight_load_30
  %tmp_11_23_3_2 = fadd float %tmp_11_23_3_1, %tmp_10_23_3_2
  %image_load_107 = load float* %image_addr_107, align 4
  %weight_load_31 = load float* %weight_addr_15, align 4
  %tmp_10_23_3_3 = fmul float %image_load_107, %weight_load_31
  %tmp_11_23_3_3 = fadd float %tmp_11_23_3_2, %tmp_10_23_3_3
  %bias_load_1 = load float* %bias_addr, align 4
  %a_assign_45 = fadd float %tmp_11_23_3_3, %bias_load_1
  %a_assign_46_to_int = bitcast float %a_assign_45 to i32
  %tmp_119 = call i8 @_ssdm_op_PartSelect.i8.i32.i32.i32(i32 %a_assign_46_to_int, i32 23, i32 30)
  %tmp_469 = trunc i32 %a_assign_46_to_int to i23
  %notlhs23 = icmp ne i8 %tmp_119, -1
  %notrhs23 = icmp eq i23 %tmp_469, 0
  %tmp_121 = or i1 %notrhs23, %notlhs23
  %tmp_122 = fcmp ogt float %a_assign_45, 0.000000e+00
  %tmp_123 = and i1 %tmp_121, %tmp_122
  %a_assign_46 = select i1 %tmp_123, float %a_assign_45, float 0.000000e+00
  store float %a_assign_46, float* %output_addr_23, align 4
  %tmp_10_23 = fmul float %image_load_96, %weight_load_16
  %tmp_11_23 = fadd float %tmp_10_23, 0.000000e+00
  %tmp_10_24_0_1 = fmul float %image_load_100, %weight_load_17
  %tmp_11_24_0_1 = fadd float %tmp_11_23, %tmp_10_24_0_1
  %tmp_10_24_0_2 = fmul float %image_load_104, %weight_load_18
  %tmp_11_24_0_2 = fadd float %tmp_11_24_0_1, %tmp_10_24_0_2
  %image_load_108 = load float* %image_addr_108, align 4
  %tmp_10_24_0_3 = fmul float %image_load_108, %weight_load_19
  %tmp_11_24_0_3 = fadd float %tmp_11_24_0_2, %tmp_10_24_0_3
  %tmp_10_24_1 = fmul float %image_load_97, %weight_load_20
  %tmp_11_24_1 = fadd float %tmp_11_24_0_3, %tmp_10_24_1
  %tmp_10_24_1_1 = fmul float %image_load_101, %weight_load_21
  %tmp_11_24_1_1 = fadd float %tmp_11_24_1, %tmp_10_24_1_1
  %tmp_10_24_1_2 = fmul float %image_load_105, %weight_load_22
  %tmp_11_24_1_2 = fadd float %tmp_11_24_1_1, %tmp_10_24_1_2
  %image_load_109 = load float* %image_addr_109, align 4
  %tmp_10_24_1_3 = fmul float %image_load_109, %weight_load_23
  %tmp_11_24_1_3 = fadd float %tmp_11_24_1_2, %tmp_10_24_1_3
  %tmp_10_24_2 = fmul float %image_load_98, %weight_load_24
  %tmp_11_24_2 = fadd float %tmp_11_24_1_3, %tmp_10_24_2
  %tmp_10_24_2_1 = fmul float %image_load_102, %weight_load_25
  %tmp_11_24_2_1 = fadd float %tmp_11_24_2, %tmp_10_24_2_1
  %tmp_10_24_2_2 = fmul float %image_load_106, %weight_load_26
  %tmp_11_24_2_2 = fadd float %tmp_11_24_2_1, %tmp_10_24_2_2
  %image_load_110 = load float* %image_addr_110, align 4
  %tmp_10_24_2_3 = fmul float %image_load_110, %weight_load_27
  %tmp_11_24_2_3 = fadd float %tmp_11_24_2_2, %tmp_10_24_2_3
  %tmp_10_24_3 = fmul float %image_load_99, %weight_load_28
  %tmp_11_24_3 = fadd float %tmp_11_24_2_3, %tmp_10_24_3
  %tmp_10_24_3_1 = fmul float %image_load_103, %weight_load_29
  %tmp_11_24_3_1 = fadd float %tmp_11_24_3, %tmp_10_24_3_1
  %tmp_10_24_3_2 = fmul float %image_load_107, %weight_load_30
  %tmp_11_24_3_2 = fadd float %tmp_11_24_3_1, %tmp_10_24_3_2
  %image_load_111 = load float* %image_addr_111, align 4
  %tmp_10_24_3_3 = fmul float %image_load_111, %weight_load_31
  %tmp_11_24_3_3 = fadd float %tmp_11_24_3_2, %tmp_10_24_3_3
  %a_assign_47 = fadd float %tmp_11_24_3_3, %bias_load_1
  %a_assign_48_to_int = bitcast float %a_assign_47 to i32
  %tmp_124 = call i8 @_ssdm_op_PartSelect.i8.i32.i32.i32(i32 %a_assign_48_to_int, i32 23, i32 30)
  %tmp_470 = trunc i32 %a_assign_48_to_int to i23
  %notlhs24 = icmp ne i8 %tmp_124, -1
  %notrhs24 = icmp eq i23 %tmp_470, 0
  %tmp_126 = or i1 %notrhs24, %notlhs24
  %tmp_127 = fcmp ogt float %a_assign_47, 0.000000e+00
  %tmp_128 = and i1 %tmp_126, %tmp_127
  %a_assign_48 = select i1 %tmp_128, float %a_assign_47, float 0.000000e+00
  store float %a_assign_48, float* %output_addr_24, align 4
  %tmp_10_24 = fmul float %image_load_100, %weight_load_16
  %tmp_11_24 = fadd float %tmp_10_24, 0.000000e+00
  %tmp_10_25_0_1 = fmul float %image_load_104, %weight_load_17
  %tmp_11_25_0_1 = fadd float %tmp_11_24, %tmp_10_25_0_1
  %tmp_10_25_0_2 = fmul float %image_load_108, %weight_load_18
  %tmp_11_25_0_2 = fadd float %tmp_11_25_0_1, %tmp_10_25_0_2
  %image_load_112 = load float* %image_addr_112, align 4
  %tmp_10_25_0_3 = fmul float %image_load_112, %weight_load_19
  %tmp_11_25_0_3 = fadd float %tmp_11_25_0_2, %tmp_10_25_0_3
  %tmp_10_25_1 = fmul float %image_load_101, %weight_load_20
  %tmp_11_25_1 = fadd float %tmp_11_25_0_3, %tmp_10_25_1
  %tmp_10_25_1_1 = fmul float %image_load_105, %weight_load_21
  %tmp_11_25_1_1 = fadd float %tmp_11_25_1, %tmp_10_25_1_1
  %tmp_10_25_1_2 = fmul float %image_load_109, %weight_load_22
  %tmp_11_25_1_2 = fadd float %tmp_11_25_1_1, %tmp_10_25_1_2
  %image_load_113 = load float* %image_addr_113, align 4
  %tmp_10_25_1_3 = fmul float %image_load_113, %weight_load_23
  %tmp_11_25_1_3 = fadd float %tmp_11_25_1_2, %tmp_10_25_1_3
  %tmp_10_25_2 = fmul float %image_load_102, %weight_load_24
  %tmp_11_25_2 = fadd float %tmp_11_25_1_3, %tmp_10_25_2
  %tmp_10_25_2_1 = fmul float %image_load_106, %weight_load_25
  %tmp_11_25_2_1 = fadd float %tmp_11_25_2, %tmp_10_25_2_1
  %tmp_10_25_2_2 = fmul float %image_load_110, %weight_load_26
  %tmp_11_25_2_2 = fadd float %tmp_11_25_2_1, %tmp_10_25_2_2
  %image_load_114 = load float* %image_addr_114, align 4
  %tmp_10_25_2_3 = fmul float %image_load_114, %weight_load_27
  %tmp_11_25_2_3 = fadd float %tmp_11_25_2_2, %tmp_10_25_2_3
  %tmp_10_25_3 = fmul float %image_load_103, %weight_load_28
  %tmp_11_25_3 = fadd float %tmp_11_25_2_3, %tmp_10_25_3
  %tmp_10_25_3_1 = fmul float %image_load_107, %weight_load_29
  %tmp_11_25_3_1 = fadd float %tmp_11_25_3, %tmp_10_25_3_1
  %tmp_10_25_3_2 = fmul float %image_load_111, %weight_load_30
  %tmp_11_25_3_2 = fadd float %tmp_11_25_3_1, %tmp_10_25_3_2
  %image_load_115 = load float* %image_addr_115, align 4
  %tmp_10_25_3_3 = fmul float %image_load_115, %weight_load_31
  %tmp_11_25_3_3 = fadd float %tmp_11_25_3_2, %tmp_10_25_3_3
  %a_assign_49 = fadd float %tmp_11_25_3_3, %bias_load_1
  %a_assign_50_to_int = bitcast float %a_assign_49 to i32
  %tmp_129 = call i8 @_ssdm_op_PartSelect.i8.i32.i32.i32(i32 %a_assign_50_to_int, i32 23, i32 30)
  %tmp_471 = trunc i32 %a_assign_50_to_int to i23
  %notlhs25 = icmp ne i8 %tmp_129, -1
  %notrhs25 = icmp eq i23 %tmp_471, 0
  %tmp_131 = or i1 %notrhs25, %notlhs25
  %tmp_132 = fcmp ogt float %a_assign_49, 0.000000e+00
  %tmp_133 = and i1 %tmp_131, %tmp_132
  %a_assign_50 = select i1 %tmp_133, float %a_assign_49, float 0.000000e+00
  store float %a_assign_50, float* %output_addr_25, align 4
  %tmp_10_25 = fmul float %image_load_104, %weight_load_16
  %tmp_11_25 = fadd float %tmp_10_25, 0.000000e+00
  %tmp_10_26_0_1 = fmul float %image_load_108, %weight_load_17
  %tmp_11_26_0_1 = fadd float %tmp_11_25, %tmp_10_26_0_1
  %tmp_10_26_0_2 = fmul float %image_load_112, %weight_load_18
  %tmp_11_26_0_2 = fadd float %tmp_11_26_0_1, %tmp_10_26_0_2
  %image_load_116 = load float* %image_addr_116, align 4
  %tmp_10_26_0_3 = fmul float %image_load_116, %weight_load_19
  %tmp_11_26_0_3 = fadd float %tmp_11_26_0_2, %tmp_10_26_0_3
  %tmp_10_26_1 = fmul float %image_load_105, %weight_load_20
  %tmp_11_26_1 = fadd float %tmp_11_26_0_3, %tmp_10_26_1
  %tmp_10_26_1_1 = fmul float %image_load_109, %weight_load_21
  %tmp_11_26_1_1 = fadd float %tmp_11_26_1, %tmp_10_26_1_1
  %tmp_10_26_1_2 = fmul float %image_load_113, %weight_load_22
  %tmp_11_26_1_2 = fadd float %tmp_11_26_1_1, %tmp_10_26_1_2
  %image_load_117 = load float* %image_addr_117, align 4
  %tmp_10_26_1_3 = fmul float %image_load_117, %weight_load_23
  %tmp_11_26_1_3 = fadd float %tmp_11_26_1_2, %tmp_10_26_1_3
  %tmp_10_26_2 = fmul float %image_load_106, %weight_load_24
  %tmp_11_26_2 = fadd float %tmp_11_26_1_3, %tmp_10_26_2
  %tmp_10_26_2_1 = fmul float %image_load_110, %weight_load_25
  %tmp_11_26_2_1 = fadd float %tmp_11_26_2, %tmp_10_26_2_1
  %tmp_10_26_2_2 = fmul float %image_load_114, %weight_load_26
  %tmp_11_26_2_2 = fadd float %tmp_11_26_2_1, %tmp_10_26_2_2
  %image_load_118 = load float* %image_addr_118, align 4
  %tmp_10_26_2_3 = fmul float %image_load_118, %weight_load_27
  %tmp_11_26_2_3 = fadd float %tmp_11_26_2_2, %tmp_10_26_2_3
  %tmp_10_26_3 = fmul float %image_load_107, %weight_load_28
  %tmp_11_26_3 = fadd float %tmp_11_26_2_3, %tmp_10_26_3
  %tmp_10_26_3_1 = fmul float %image_load_111, %weight_load_29
  %tmp_11_26_3_1 = fadd float %tmp_11_26_3, %tmp_10_26_3_1
  %tmp_10_26_3_2 = fmul float %image_load_115, %weight_load_30
  %tmp_11_26_3_2 = fadd float %tmp_11_26_3_1, %tmp_10_26_3_2
  %image_load_119 = load float* %image_addr_119, align 4
  %tmp_10_26_3_3 = fmul float %image_load_119, %weight_load_31
  %tmp_11_26_3_3 = fadd float %tmp_11_26_3_2, %tmp_10_26_3_3
  %a_assign_51 = fadd float %tmp_11_26_3_3, %bias_load_1
  %a_assign_52_to_int = bitcast float %a_assign_51 to i32
  %tmp_134 = call i8 @_ssdm_op_PartSelect.i8.i32.i32.i32(i32 %a_assign_52_to_int, i32 23, i32 30)
  %tmp_472 = trunc i32 %a_assign_52_to_int to i23
  %notlhs26 = icmp ne i8 %tmp_134, -1
  %notrhs26 = icmp eq i23 %tmp_472, 0
  %tmp_136 = or i1 %notrhs26, %notlhs26
  %tmp_137 = fcmp ogt float %a_assign_51, 0.000000e+00
  %tmp_138 = and i1 %tmp_136, %tmp_137
  %a_assign_52 = select i1 %tmp_138, float %a_assign_51, float 0.000000e+00
  store float %a_assign_52, float* %output_addr_26, align 4
  %tmp_10_26 = fmul float %image_load_108, %weight_load_16
  %tmp_11_26 = fadd float %tmp_10_26, 0.000000e+00
  %tmp_10_27_0_1 = fmul float %image_load_112, %weight_load_17
  %tmp_11_27_0_1 = fadd float %tmp_11_26, %tmp_10_27_0_1
  %tmp_10_27_0_2 = fmul float %image_load_116, %weight_load_18
  %tmp_11_27_0_2 = fadd float %tmp_11_27_0_1, %tmp_10_27_0_2
  %image_load_120 = load float* %image_addr_120, align 4
  %tmp_10_27_0_3 = fmul float %image_load_120, %weight_load_19
  %tmp_11_27_0_3 = fadd float %tmp_11_27_0_2, %tmp_10_27_0_3
  %tmp_10_27_1 = fmul float %image_load_109, %weight_load_20
  %tmp_11_27_1 = fadd float %tmp_11_27_0_3, %tmp_10_27_1
  %tmp_10_27_1_1 = fmul float %image_load_113, %weight_load_21
  %tmp_11_27_1_1 = fadd float %tmp_11_27_1, %tmp_10_27_1_1
  %tmp_10_27_1_2 = fmul float %image_load_117, %weight_load_22
  %tmp_11_27_1_2 = fadd float %tmp_11_27_1_1, %tmp_10_27_1_2
  %image_load_121 = load float* %image_addr_121, align 4
  %tmp_10_27_1_3 = fmul float %image_load_121, %weight_load_23
  %tmp_11_27_1_3 = fadd float %tmp_11_27_1_2, %tmp_10_27_1_3
  %tmp_10_27_2 = fmul float %image_load_110, %weight_load_24
  %tmp_11_27_2 = fadd float %tmp_11_27_1_3, %tmp_10_27_2
  %tmp_10_27_2_1 = fmul float %image_load_114, %weight_load_25
  %tmp_11_27_2_1 = fadd float %tmp_11_27_2, %tmp_10_27_2_1
  %tmp_10_27_2_2 = fmul float %image_load_118, %weight_load_26
  %tmp_11_27_2_2 = fadd float %tmp_11_27_2_1, %tmp_10_27_2_2
  %image_load_122 = load float* %image_addr_122, align 4
  %tmp_10_27_2_3 = fmul float %image_load_122, %weight_load_27
  %tmp_11_27_2_3 = fadd float %tmp_11_27_2_2, %tmp_10_27_2_3
  %tmp_10_27_3 = fmul float %image_load_111, %weight_load_28
  %tmp_11_27_3 = fadd float %tmp_11_27_2_3, %tmp_10_27_3
  %tmp_10_27_3_1 = fmul float %image_load_115, %weight_load_29
  %tmp_11_27_3_1 = fadd float %tmp_11_27_3, %tmp_10_27_3_1
  %tmp_10_27_3_2 = fmul float %image_load_119, %weight_load_30
  %tmp_11_27_3_2 = fadd float %tmp_11_27_3_1, %tmp_10_27_3_2
  %image_load_123 = load float* %image_addr_123, align 4
  %tmp_10_27_3_3 = fmul float %image_load_123, %weight_load_31
  %tmp_11_27_3_3 = fadd float %tmp_11_27_3_2, %tmp_10_27_3_3
  %a_assign_53 = fadd float %tmp_11_27_3_3, %bias_load_1
  %a_assign_54_to_int = bitcast float %a_assign_53 to i32
  %tmp_139 = call i8 @_ssdm_op_PartSelect.i8.i32.i32.i32(i32 %a_assign_54_to_int, i32 23, i32 30)
  %tmp_473 = trunc i32 %a_assign_54_to_int to i23
  %notlhs27 = icmp ne i8 %tmp_139, -1
  %notrhs27 = icmp eq i23 %tmp_473, 0
  %tmp_141 = or i1 %notrhs27, %notlhs27
  %tmp_142 = fcmp ogt float %a_assign_53, 0.000000e+00
  %tmp_143 = and i1 %tmp_141, %tmp_142
  %a_assign_54 = select i1 %tmp_143, float %a_assign_53, float 0.000000e+00
  store float %a_assign_54, float* %output_addr_27, align 4
  %tmp_10_27 = fmul float %image_load_112, %weight_load_16
  %tmp_11_27 = fadd float %tmp_10_27, 0.000000e+00
  %tmp_10_28_0_1 = fmul float %image_load_116, %weight_load_17
  %tmp_11_28_0_1 = fadd float %tmp_11_27, %tmp_10_28_0_1
  %tmp_10_28_0_2 = fmul float %image_load_120, %weight_load_18
  %tmp_11_28_0_2 = fadd float %tmp_11_28_0_1, %tmp_10_28_0_2
  %image_load_124 = load float* %image_addr_124, align 4
  %tmp_10_28_0_3 = fmul float %image_load_124, %weight_load_19
  %tmp_11_28_0_3 = fadd float %tmp_11_28_0_2, %tmp_10_28_0_3
  %tmp_10_28_1 = fmul float %image_load_113, %weight_load_20
  %tmp_11_28_1 = fadd float %tmp_11_28_0_3, %tmp_10_28_1
  %tmp_10_28_1_1 = fmul float %image_load_117, %weight_load_21
  %tmp_11_28_1_1 = fadd float %tmp_11_28_1, %tmp_10_28_1_1
  %tmp_10_28_1_2 = fmul float %image_load_121, %weight_load_22
  %tmp_11_28_1_2 = fadd float %tmp_11_28_1_1, %tmp_10_28_1_2
  %image_load_125 = load float* %image_addr_125, align 4
  %tmp_10_28_1_3 = fmul float %image_load_125, %weight_load_23
  %tmp_11_28_1_3 = fadd float %tmp_11_28_1_2, %tmp_10_28_1_3
  %tmp_10_28_2 = fmul float %image_load_114, %weight_load_24
  %tmp_11_28_2 = fadd float %tmp_11_28_1_3, %tmp_10_28_2
  %tmp_10_28_2_1 = fmul float %image_load_118, %weight_load_25
  %tmp_11_28_2_1 = fadd float %tmp_11_28_2, %tmp_10_28_2_1
  %tmp_10_28_2_2 = fmul float %image_load_122, %weight_load_26
  %tmp_11_28_2_2 = fadd float %tmp_11_28_2_1, %tmp_10_28_2_2
  %image_load_126 = load float* %image_addr_126, align 4
  %tmp_10_28_2_3 = fmul float %image_load_126, %weight_load_27
  %tmp_11_28_2_3 = fadd float %tmp_11_28_2_2, %tmp_10_28_2_3
  %tmp_10_28_3 = fmul float %image_load_115, %weight_load_28
  %tmp_11_28_3 = fadd float %tmp_11_28_2_3, %tmp_10_28_3
  %tmp_10_28_3_1 = fmul float %image_load_119, %weight_load_29
  %tmp_11_28_3_1 = fadd float %tmp_11_28_3, %tmp_10_28_3_1
  %tmp_10_28_3_2 = fmul float %image_load_123, %weight_load_30
  %tmp_11_28_3_2 = fadd float %tmp_11_28_3_1, %tmp_10_28_3_2
  %image_load_127 = load float* %image_addr_127, align 4
  %tmp_10_28_3_3 = fmul float %image_load_127, %weight_load_31
  %tmp_11_28_3_3 = fadd float %tmp_11_28_3_2, %tmp_10_28_3_3
  %a_assign_55 = fadd float %tmp_11_28_3_3, %bias_load_1
  %a_assign_56_to_int = bitcast float %a_assign_55 to i32
  %tmp_144 = call i8 @_ssdm_op_PartSelect.i8.i32.i32.i32(i32 %a_assign_56_to_int, i32 23, i32 30)
  %tmp_474 = trunc i32 %a_assign_56_to_int to i23
  %notlhs28 = icmp ne i8 %tmp_144, -1
  %notrhs28 = icmp eq i23 %tmp_474, 0
  %tmp_146 = or i1 %notrhs28, %notlhs28
  %tmp_147 = fcmp ogt float %a_assign_55, 0.000000e+00
  %tmp_148 = and i1 %tmp_146, %tmp_147
  %a_assign_56 = select i1 %tmp_148, float %a_assign_55, float 0.000000e+00
  store float %a_assign_56, float* %output_addr_28, align 4
  %empty_4 = call i32 (...)* @_ssdm_op_SpecRegionEnd([12 x i8]* @p_str, i32 %tmp_1) nounwind
  br label %.preheader

; <label>:1                                       ; preds = %.preheader
  ret void
}

define weak void @_ssdm_op_SpecTopModule(...) {
entry:
  ret void
}

define weak i32 @_ssdm_op_SpecRegionEnd(...) {
entry:
  ret i32 0
}

define weak i32 @_ssdm_op_SpecRegionBegin(...) {
entry:
  ret i32 0
}

define weak void @_ssdm_op_SpecPipeline(...) nounwind {
entry:
  ret void
}

define weak i32 @_ssdm_op_SpecLoopTripCount(...) {
entry:
  ret i32 0
}

define weak void @_ssdm_op_SpecLoopName(...) nounwind {
entry:
  ret void
}

define weak void @_ssdm_op_SpecBitsMap(...) {
entry:
  ret void
}

define weak i8 @_ssdm_op_PartSelect.i8.i32.i32.i32(i32, i32, i32) nounwind readnone {
entry:
  %empty = call i32 @llvm.part.select.i32(i32 %0, i32 %1, i32 %2)
  %empty_5 = trunc i32 %empty to i8
  ret i8 %empty_5
}

declare i23 @_ssdm_op_PartSelect.i23.i32.i32.i32(i32, i32, i32) nounwind readnone

define weak i64 @_ssdm_op_BitConcatenate.i64.i60.i4(i60, i4) nounwind readnone {
entry:
  %empty = zext i60 %0 to i64
  %empty_6 = zext i4 %1 to i64
  %empty_7 = shl i64 %empty, 4
  %empty_8 = or i64 %empty_7, %empty_6
  ret i64 %empty_8
}

define weak i64 @_ssdm_op_BitConcatenate.i64.i54.i10(i54, i10) nounwind readnone {
entry:
  %empty = zext i54 %0 to i64
  %empty_9 = zext i10 %1 to i64
  %empty_10 = shl i64 %empty, 10
  %empty_11 = or i64 %empty_10, %empty_9
  ret i64 %empty_11
}

define weak i10 @_ssdm_op_BitConcatenate.i10.i5.i5(i5, i5) nounwind readnone {
entry:
  %empty = zext i5 %0 to i10
  %empty_12 = zext i5 %1 to i10
  %empty_13 = shl i10 %empty, 5
  %empty_14 = or i10 %empty_13, %empty_12
  ret i10 %empty_14
}

!opencl.kernels = !{!0, !7}
!hls.encrypted.func = !{}
!llvm.map.gv = !{}

!0 = metadata !{null, metadata !1, metadata !2, metadata !3, metadata !4, metadata !5, metadata !6}
!1 = metadata !{metadata !"kernel_arg_addr_space", i32 0}
!2 = metadata !{metadata !"kernel_arg_access_qual", metadata !"none"}
!3 = metadata !{metadata !"kernel_arg_type", metadata !"float"}
!4 = metadata !{metadata !"kernel_arg_type_qual", metadata !""}
!5 = metadata !{metadata !"kernel_arg_name", metadata !"a"}
!6 = metadata !{metadata !"reqd_work_group_size", i32 1, i32 1, i32 1}
!7 = metadata !{null, metadata !8, metadata !9, metadata !10, metadata !11, metadata !12, metadata !6}
!8 = metadata !{metadata !"kernel_arg_addr_space", i32 1, i32 1, i32 1, i32 1}
!9 = metadata !{metadata !"kernel_arg_access_qual", metadata !"none", metadata !"none", metadata !"none", metadata !"none"}
!10 = metadata !{metadata !"kernel_arg_type", metadata !"float [29][8]*", metadata !"float [32][1]*", metadata !"float [4][1][8]*", metadata !"float*"}
!11 = metadata !{metadata !"kernel_arg_type_qual", metadata !"", metadata !"", metadata !"", metadata !""}
!12 = metadata !{metadata !"kernel_arg_name", metadata !"output", metadata !"image", metadata !"weight", metadata !"bias"}
!13 = metadata !{metadata !14}
!14 = metadata !{i32 0, i32 31, metadata !15}
!15 = metadata !{metadata !16}
!16 = metadata !{metadata !"output", metadata !17, metadata !"float", i32 0, i32 31}
!17 = metadata !{metadata !18, metadata !18, metadata !19}
!18 = metadata !{i32 0, i32 28, i32 1}
!19 = metadata !{i32 0, i32 7, i32 1}
!20 = metadata !{metadata !21}
!21 = metadata !{i32 0, i32 31, metadata !22}
!22 = metadata !{metadata !23}
!23 = metadata !{metadata !"image", metadata !24, metadata !"float", i32 0, i32 31}
!24 = metadata !{metadata !25, metadata !25, metadata !26}
!25 = metadata !{i32 0, i32 31, i32 1}
!26 = metadata !{i32 0, i32 0, i32 1}
!27 = metadata !{metadata !28}
!28 = metadata !{i32 0, i32 31, metadata !29}
!29 = metadata !{metadata !30}
!30 = metadata !{metadata !"weight", metadata !31, metadata !"float", i32 0, i32 31}
!31 = metadata !{metadata !32, metadata !32, metadata !26, metadata !19}
!32 = metadata !{i32 0, i32 3, i32 1}
!33 = metadata !{metadata !34}
!34 = metadata !{i32 0, i32 31, metadata !35}
!35 = metadata !{metadata !36}
!36 = metadata !{metadata !"bias", metadata !37, metadata !"float", i32 0, i32 31}
!37 = metadata !{metadata !19}
